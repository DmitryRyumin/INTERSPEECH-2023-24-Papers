# INTERSPEECH-2023-Papers

![GitHub repo size](https://img.shields.io/github/repo-size/DmitryRyumin/INTERSPEECH-2023-Papers)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers/blob/main/LICENSE)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers/blob/main/README.md)
![GitHub last commit](https://img.shields.io/github/last-commit/DmitryRyumin/INTERSPEECH-2023-Papers)
<!-- ![Papers Implemented](https://badgen.net/badge/Papers%20implemented/0) -->

---

INTERSPEECH 2023 Papers: A complete collection of influential and exciting research papers from the [*INTERSPEECH 2023*](https://interspeech2023.org/) conference. Explore the latest advances in speech and language processing. Code included. :star: the repository to support the advancement of speech technology!

<p align="center">
    <a href="https://interspeech2023.org/" target="_blank">
        <img width="400" src="https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers/blob/main/images/Interspeech2023-Stacked-Colour.png" alt="Interspeech 2023">
    </a>
<p>

---

## Contributors

<a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=DmitryRyumin/INTERSPEECH-2023-Papers" />
</a>

<br />
<br />

Contributions to improve the completeness of this list are greatly appreciated. If you come across any overlooked papers, please **feel free to [*create pull requests*](https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers/pulls), [*open issues*](https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers/issues) or contact me via [*email*](mailto:ryumin.d@iias.spb.su)**. Your participation is crucial to making this repository even better.

---

## Papers

### Speech Synthesis: Prosody and Emotion

| **No** | **Title** | **Repo** | **Paper** |
| ------ | --------- |:--------:|:---------:|
| 1 | Emotional Talking Head Generation based on Memory-Sharing and Attention-Augmented Networks | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.03594-b31b1b.svg)](https://arxiv.org/abs/2306.03594) |
| 2 | Speech Synthesis with Self-Supervisedly Learnt Prosodic Representations | :heavy_minus_sign: | :heavy_minus_sign: |
| 3 | EmoMix: Emotion Mixing via Diffusion Models for Emotional Speech Synthesis | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.00648-b31b1b.svg)](https://arxiv.org/abs/2306.00648) |
| 4 | Laughter Synthesis using Pseudo Phonetic Tokens with a Large-scale In-the-wild Laughter Corpus | [![GitHub](https://img.shields.io/github/stars/Aria-K-Alethia/laughter-synthesis)](https://github.com/Aria-K-Alethia/laughter-synthesis) | [![arXiv](https://img.shields.io/badge/arXiv-2305.12442-b31b1b.svg)](https://arxiv.org/abs/2305.12442) |
| 5 | Explicit Intensity Control for Accented Text-to-speech | [![GitHub](https://img.shields.io/github/stars/ttslr/Ai-TTS)](https://github.com/ttslr/Ai-TTS) | [![arXiv](https://img.shields.io/badge/arXiv-2210.15364-b31b1b.svg)](https://arxiv.org/abs/2210.15364) |
| 6 | Comparing Normalizing Flows and Diffusion Models for Prosody and Acoustic Modelling in Text-to-speech | :heavy_minus_sign: | :heavy_minus_sign: |

### Statistical Machine Translation

| **No** | **Title** | **Repo** | **Paper** |
| ------ | --------- |:--------:|:---------:|
| 7 | Modular Speech-to-Text Translation for Zero-Shot Cross-Modal Transfer | :heavy_minus_sign: | :heavy_minus_sign: |
| 8 | Improving Isochronous Machine Translation with Target Factors and Auxiliary Counters | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2305.13204-b31b1b.svg)](https://arxiv.org/abs/2305.13204) |
| 9 | StyleS2ST: Zero-shot Style Transfer for Direct Speech-to-speech Translation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://styles2st.github.io/StyleS2ST/) | [![arXiv](https://img.shields.io/badge/arXiv-2305.17732-b31b1b.svg)](https://arxiv.org/abs/2305.17732) |
| 10 | Joint Speech Translation and Named Entity Recognition | [![GitHub](https://img.shields.io/github/stars/hlt-mt/FBK-fairseq)](https://github.com/hlt-mt/FBK-fairseq/blob/master/fbk_works/JOINT_ST_NER2023.md) | [![arXiv](https://img.shields.io/badge/arXiv-2210.11987-b31b1b.svg)](https://arxiv.org/abs/2210.11987) |
| 11 | Analysis of Acoustic information in End-to-End Spoken Language Translation | :heavy_minus_sign: | :heavy_minus_sign: |
| 12 | LAMASSU: A Streaming Language-Agnostic Multilingual Speech Recognition and Translation Model Using Neural Transducers | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2211.02809-b31b1b.svg)](https://arxiv.org/abs/2211.02809) |

### Self-Supervised Learning in ASR

| **No** | **Title** | **Repo** | **Paper** |
| ------ | --------- |:--------:|:---------:|
| 13 | DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models | [![GitHub](https://img.shields.io/github/stars/pyf98/DPHuBERT)](https://github.com/pyf98/DPHuBERT) | [![arXiv](https://img.shields.io/badge/arXiv-2305.17651-b31b1b.svg)](https://arxiv.org/abs/2305.17651) |
| 14 | Automatic Data Augmentation for Domain Adapted Fine-Tuning of Self-Supervised Speech Representations | [![GitHub](https://img.shields.io/github/stars/salah-zaiem/augmentations_adaptation)](https://github.com/salah-zaiem/augmentations_adaptation) | [![arXiv](https://img.shields.io/badge/arXiv-2306.00481-b31b1b.svg)](https://arxiv.org/abs/2306.00481) |
| 15 | Dual Acoustic Linguistic Self-supervised Representation Learning for Cross-Domain Speech Recognition | :heavy_minus_sign: | :heavy_minus_sign: |
| 16 | O-1: Self-training with Oracle and 1-best Hypothesis | :heavy_minus_sign: | :heavy_minus_sign: |
| 17 | MT4SSL: Boosting Self-Supervised Speech Representation Learning by Integrating Multiple Targets | [![GitHub](https://img.shields.io/github/stars/ddlBoJack/MT4SSL)](https://github.com/ddlBoJack/MT4SSL) | [![arXiv](https://img.shields.io/badge/arXiv-2211.07321-b31b1b.svg)](https://arxiv.org/abs/2211.07321) |
| 18 | Comparison of Multilingual Self-Supervised and Weakly-Supervised Speech Pre-Training for Adaptation to Unseen Languages | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2305.12606-b31b1b.svg)](https://arxiv.org/abs/2305.12606) |

### Prosody

| **No** | **Title** | **Repo** | **Paper** |
| ------ | --------- |:--------:|:---------:|
| 19 | Chinese EFL Learners' Perception of English Prosodic Focus | :heavy_minus_sign: | :heavy_minus_sign: |
| 20 | Pitch Accent Variation and the Interpretation of Rising and Falling Intonation in American English | :heavy_minus_sign: | :heavy_minus_sign: |
| 21 | Tonal Coarticulation as a Cue for Upcoming Prosodic Boundary | :heavy_minus_sign: | :heavy_minus_sign: |
| 22 | Alignment of Beat Gestures and Prosodic Prominence in German | :heavy_minus_sign: | :heavy_minus_sign: |
| 23 | Creak Prevalence and Prosodic Context in Australian English | :heavy_minus_sign: | :heavy_minus_sign: |
| 24 | Speech Reduction: Position within French Prosodic Structure | :heavy_minus_sign: | :heavy_minus_sign: |

### Speech Production

| **No** | **Title** | **Repo** | **Paper** |
| ------ | --------- |:--------:|:---------:|
| 25 | Transvelar Nasal Coupling Contributing to Speaker Characteristics in Non-nasal Vowels | :heavy_minus_sign: | :heavy_minus_sign: |
| 26 | Speech Synthesis from Articulatory Movements Recorded by Real-time MRI | :heavy_minus_sign: | :heavy_minus_sign: |
| 27 |  The ART of Conversation: Measuring Phonetic Convergence and Deliberate Imitation in L2-Speech with a Siamese RNN | [![GitHub](https://img.shields.io/github/stars/byronthecoder/S-RNN-4-ART)](https://github.com/byronthecoder/S-RNN-4-ART) | [![arXiv](https://img.shields.io/badge/arXiv-2306.05088-b31b1b.svg)](https://arxiv.org/abs/2306.05088) |
| 28 | Did You See that? Exploring the Role of Vision in the Development of Consonant Feature Contrasts in Children with Cochlear Implants | :heavy_minus_sign: | :heavy_minus_sign: |

### Dysarthric Speech Assessment

| **No** | **Title** | **Repo** | **Paper** |
| ------ | --------- |:--------:|:---------:|
| 29 | Automatic Assessments of Dysarthric Speech: the Usability of Acoustic-phonetic Features | :heavy_minus_sign: | :heavy_minus_sign: |
| 30 | Classification of Multi-class Vowels and Fricatives from Patients Having Amyotrophic Lateral Sclerosis with Varied Levels of Dysarthria Severity | :heavy_minus_sign: | :heavy_minus_sign: |
| 31 | Parameter-efficient Dysarthric Speech Recognition using Adapter Fusion and Householder Transformation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.07090-b31b1b.svg)](https://arxiv.org/abs/2306.07090) |
| 32 | Few-shot Dysarthric Speech Recognition with Text-to-Speech Data Augmentation | :heavy_minus_sign: | [![idiap](https://img.shields.io/badge/idiap.ch.5055-FF6A00.svg)](http://publications.idiap.ch/index.php/publications/show/5055) |
| 33 | Latent Phrase Matching for Dysarthric Speech | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.05446-b31b1b.svg)](https://arxiv.org/abs/2306.05446) |
| 34 | Speech Intelligibility Assessment of Dysarthric Speech by using Goodness of Pronunciation with Uncertainty Quantification | [![GitHub](https://img.shields.io/github/stars/juice500ml/dysarthria-gop)](https://github.com/juice500ml/dysarthria-gop) | [![arXiv](https://img.shields.io/badge/arXiv-2305.18392-b31b1b.svg)](https://arxiv.org/abs/2305.18392) |

### Speech Coding: Transmission

| **No** | **Title** | **Repo** | **Paper** |
| ------ | --------- |:--------:|:---------:|
| 35 | CQNV: A Combination of Coarsely Quantized Bitstream and Neural Vocoder for Low Rate Speech Coding | :heavy_minus_sign: | :heavy_minus_sign: |
| 36 | Target Speech Extraction with Conditional Diffusion Model | :heavy_minus_sign: | :heavy_minus_sign: |
| 37 | Towards Fully Quantized Neural Networks For Speech Enhancement | :heavy_minus_sign: | :heavy_minus_sign: |
| 38 |  Complex Image Generation SwinTransformer Network for Audio Denoising | [![GitHub](https://img.shields.io/github/stars/YoushanZhang/CoxImgSwinTransformer)](https://github.com/YoushanZhang/CoxImgSwinTransformer) | :heavy_minus_sign: |

### Speech Recognition: Signal Processing, Acoustic Modeling, Robustness, Adaptation

| **No** | **Title** | **Repo** | **Paper** |
| ------ | --------- |:--------:|:---------:|
| 39 | Using Text Injection to Improve Recognition of Personal Identifiers in Speech | :heavy_minus_sign: | :heavy_minus_sign: |
| 40 | Investigating Wav2Vec2 Context Representations and the Effects of Fine-tuning, a Case-study of a Finnish Model | [![GitHub](https://img.shields.io/github/stars/aalto-speech/Wav2vec2Interpretation)](https://github.com/aalto-speech/Wav2vec2Interpretation) | :heavy_minus_sign: |
| 41 | Transformer-based Speech Recognition Models for Oral History Archives in English, German, and Czech | :heavy_minus_sign: | :heavy_minus_sign: |
| 42 | Iteratively Improving Speech Recognition and Voice Conversion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://demosamplesites.github.io/IterativeASR_VC/) | [![arXiv](https://img.shields.io/badge/arXiv-2305.15055-b31b1b.svg)](https://arxiv.org/abs/2305.15055) |
| 43 | LABERT: A Combination of Local Aggregation and Self-Supervised Speech Representation Learning for Detecting Informative Hidden Units in Low-Resource ASR Systems | :heavy_minus_sign: | [![nottingham-repo](https://img.shields.io/badge/nottingham-22183323-1A296B.svg)](https://nottingham-repository.worktribe.com/output/22183323) |
| 44 | TranUSR: Phoneme-to-word Transcoder Based Unified Speech Representation Learning for Cross-lingual Speech Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2305.13629-b31b1b.svg)](https://arxiv.org/abs/2305.13629) |
| 45 | Dual-Mode NAM: Effective Top-K Context Injection for End-to-End ASR | :heavy_minus_sign: | :heavy_minus_sign: |
| 46 | GhostRNN: Reducing State Redundancy in RNN with Cheap Operations | :heavy_minus_sign: | :heavy_minus_sign: |
| 47 | Task-Agnostic Structured Pruning of Speech Representation Models | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.01385-b31b1b.svg)](https://arxiv.org/abs/2306.01385) |
| 48 | Factual Consistency Oriented Speech Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2302.12369-b31b1b.svg)](https://arxiv.org/abs/2302.12369) |
| 49 | Multi-Head State Space Model for Speech Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2305.12498-b31b1b.svg)](https://arxiv.org/abs/2305.12498) |
| 50 | Cascaded Multi-task Adaptive Learning Based on Neural Architecture Search | :heavy_minus_sign: | :heavy_minus_sign: |
| 51 | Probing Self-supervised Speech Models for Phonetic and Phonemic Information: a Case Study in Aspiration | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.06232-b31b1b.svg)](https://arxiv.org/abs/2306.06232) |
| 52 | Selective Biasing with Trie-based Contextual Adapters for Personalised Speech Recognition using Neural Transducers | :heavy_minus_sign: | [![Amazon Science](https://img.shields.io/badge/amazon-science-FE9901.svg)](https://www.amazon.science/publications/selective-biasing-with-trie-based-contextual-adapters-for-personalised-speech-recognition-using-neural-transducers) |

### Analysis of Speech and Audio Signals

| **No** | **Title** | **Repo** | **Paper** |
| ------ | --------- |:--------:|:---------:|
| 53 | Robust Prototype Learning for Anomalous Sound Detection | :heavy_minus_sign: | :heavy_minus_sign: |
| 54 | A Multimodal Prototypical Approach for Unsupervised Sound Classification | [![GitHub](https://img.shields.io/github/stars/sakshamsingh1/audio_text_proto)](https://github.com/sakshamsingh1/audio_text_proto) | [![arXiv](https://img.shields.io/badge/arXiv-2306.12300-b31b1b.svg)](https://arxiv.org/abs/2306.12300) |
| 55 | Robust Audio Anti-Spoofing with Fusion-Reconstruction Learning on Multi-Order Spectrograms | :heavy_minus_sign: | :heavy_minus_sign: |
| 56 | Adapting Language-Audio Models as Few-Shot Audio Learners | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2305.17719-b31b1b.svg)](https://arxiv.org/abs/2305.17719) |
| 57 | Visually-Aware Audio Captioning With Adaptive Audio-Visual Attention | [![GitHub](https://img.shields.io/github/stars/liuxubo717/V-ACT)](https://github.com/liuxubo717/V-ACT) | [![arXiv](https://img.shields.io/badge/arXiv-2210.16428-b31b1b.svg)](https://arxiv.org/abs/2210.16428) |
| 58 | TFECN: Time-Frequency Enhanced ConvNet for Audio Classification | :heavy_minus_sign: | :heavy_minus_sign: |
| 59 | Resolution Consistency Training on Time-Frequency Domain for Semi-Supervised Sound Event Detection | :heavy_minus_sign: | :heavy_minus_sign: |
| 60 | Fine-tuning Audio Spectrogram Transformer with Task-aware Adapters for Sound Event Detection | :heavy_minus_sign: | :heavy_minus_sign: |
| 61 | Small Footprint Multi-channel Network for Keyword Spotting with Centroid Based Awareness | :heavy_minus_sign: | :heavy_minus_sign: |
| 62 | Few-shot Class-incremental Audio Classification Using Adaptively-refined Prototypes | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2305.18045-b31b1b.svg)](https://arxiv.org/abs/2305.18045) |
| 63 | Interpretable Latent Space Using Space-Filling Curves for Phonetic Analysis in Voice Conversion | [![GitLab](https://img.shields.io/gitlab/stars/speech-interaction-technology-aalto-university/sfvq)](https://gitlab.com/speech-interaction-technology-aalto-university/sfvq) | [![Aalto](https://img.shields.io/badge/aalto-fi-005EB8.svg)](https://research.aalto.fi/en/publications/interpretable-latent-space-using-space-filling-curves-for-phoneti) |
| 64 | Topological Data Analysis for Speech Processing | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://topohubert.github.io/speech-topology-webpages/) | [![arXiv](https://img.shields.io/badge/arXiv-2211.17223-b31b1b.svg)](https://arxiv.org/abs/2211.17223) |
| 65 | Recycle-and-Distill: Universal Compression Strategy for Transformer-based Speech SSL Models with Attention Map Reusing and Masking Distillation | [![GitHub](https://img.shields.io/github/stars/sungnyun/ARMHuBERT)](https://github.com/sungnyun/ARMHuBERT) | [![arXiv](https://img.shields.io/badge/arXiv-2305.11685-b31b1b.svg)](https://arxiv.org/abs/2305.11685) |
| 66 | Personalized Acoustic Scene Classification in Ultra-low Power Embedded Devices using Privacy-preserving Data Augmentation | :heavy_minus_sign: | :heavy_minus_sign: |
| 67 | Background Domain Switch: A Novel Data Augmentation Technique for Robust Sound Event Detection | :heavy_minus_sign: | :heavy_minus_sign: |
| 68 | Joint Prediction of Audio Event and Annoyance Rating in an Urban Soundscape by Hierarchical Graph Representation Learning | [![GitHub](https://img.shields.io/github/stars/Yuanbo2020/HGRL)](https://github.com/Yuanbo2020/HGRL) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](http://personal.ee.surrey.ac.uk/Personal/W.Wang/papers/Hou%20etal_INTERSPEECH_2023.pdf) |
| 69 | Anomalous Sound Detection Using Self-Attention-Based Frequency Pattern Analysis of Machine Sounds | :heavy_minus_sign: | :heavy_minus_sign: |
| 70 | Improving Audio-Text Retrieval via Hierarchical Cross-Modal Interaction and Auxiliary Captions | :heavy_minus_sign: | :heavy_minus_sign: |
| 71 | Ontology-aware Learning and Evaluation for Audio Tagging | [![GitHub](https://img.shields.io/github/stars/haoheliu/ontology-aware-audio-tagging)](https://github.com/haoheliu/ontology-aware-audio-tagging) | [![arXiv](https://img.shields.io/badge/arXiv-2211.12195-b31b1b.svg)](https://arxiv.org/abs/2211.12195) |
| 72 | Differential Privacy enabled Dementia Classification: An Exploration of the Privacy-Accuracy Trade-off in Speech Signal Data | :heavy_minus_sign: | :heavy_minus_sign: |
| 73 | Learning Emotional Representations from Imbalanced Speech Data for Speech Emotion Recognition and Emotional Text-to-Speech | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://anonymous.4open.science/w/INTERSPEECH2023-F8C4/) | [![arXiv](https://img.shields.io/badge/arXiv-2306.05709-b31b1b.svg)](https://arxiv.org/abs/2306.05709) |
| 74 | Towards Multi-Lingual Audio Question Answering | :heavy_minus_sign: | :heavy_minus_sign: |

### Speech Recognition: Architecture, Search, and Linguistic Components

| **No** | **Title** | **Repo** | **Paper** |
| ------ | --------- |:--------:|:---------:|
| 75 | Diacritic Recognition Performance in Arabic ASR | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2302.14022-b31b1b.svg)](https://arxiv.org/abs/2302.14022) |
| 76 | Personalization for BERT-based Discriminative Speech Recognition Rescoring | :heavy_minus_sign: | [![Amazon Science](https://img.shields.io/badge/amazon-science-FE9901.svg)](https://www.amazon.science/publications/personalization-for-bert-based-discriminative-speech-recognition-rescoring) |
| 77 | On the N-gram Approximation of Pre-trained Language Models | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.06892-b31b1b.svg)](https://arxiv.org/abs/2306.06892) |
| 78 | Record Deduplication for Entity Distribution Modeling in ASR Transcripts | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.06246-b31b1b.svg)](https://arxiv.org/abs/2306.06246) |
| 79 | Learning When to Trust Which Teacher for Weakly Supervised ASR | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.12012-b31b1b.svg)](https://arxiv.org/abs/2306.12012) |
| 80 | Text-only Domain Adaptation using Unified Speech-Text Representation in Transducer | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.04076-b31b1b.svg)](https://arxiv.org/abs/2306.04076) |

### Speech Recognition: Technologies and Systems for New Applications

| **No** | **Title** | **Repo** | **Paper** |
| ------ | --------- |:--------:|:---------:|
| 81 | How to Estimate Model Transferability of Pre-Trained Speech Models? | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.01015-b31b1b.svg)](https://arxiv.org/abs/2306.01015) |
| 82 | Progress and Prospects for Spoken Language Technology: Results from Five Sexennial Surveys | :heavy_minus_sign: | :heavy_minus_sign: |
| 83 | Acoustic Word Embeddings for Untranscribed Target Languages with Continued Pretraining and Learned Pooling | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.02153-b31b1b.svg)](https://arxiv.org/abs/2306.02153) |
| 84 | CASA-ASR: Context-Aware Speaker-Attributed ASR |  |  |
| 85 | Unsupervised Learning of Discrete Latent Representations with Data-Adaptive Dimensionality from Continuous Speech Streams |  |  |
| 86 | AD-TUNING: An Adaptive CHILD-TUNING Approach to Efficient Hyperparameter Optimization of Child Networks for Speech Processing Tasks in the SU-PERB Benchmark |  |  |
| 87 | Distilling Knowledge from Gaussian Process Teacher to Neural Network Student |  |  |
| 88 | Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization |  |  |
| 89 | Segmental SpeechCLIP: Utilizing Pretrained Image-text Models for Audio-Visual Learning |  |  |
| 90 | Towards hate speech detection in low-resource languages: Comparing ASR to acoustic word embeddings on Wolof and Swahili |  |  |
| 91 | Mitigating Catastrophic Forgetting for Few-Shot Spoken Word Classification Through Meta-Learning |  |  |
| 92 | Online Punctuation Restoration using ELECTRA Model for streaming ASR Systems |  |  |
| 93 | Language Agnostic Data-Driven Inverse Text Normalization |  |  |
| 94 | Syllable Discovery and Cross-Lingual Generalization in a Visually Grounded, Self-Supervised Speech Model |  |  |
| 95 | Transcribing Speech as Spoken and Written Dual Text Using an Autoregressive Model |  |  |

### Lexical and Language Modeling for ASR

> Will soon be added

### Language Identification and Diarization

> Will soon be added

### Speech Quality Assessment

> Will soon be added

### Feature Modeling for ASR

> Will soon be added

### Interfacing Speech Technology and Phonetics

> Will soon be added

### Speech Synthesis: Multilinguality

> Will soon be added

### Speech Emotion Recognition

> Will soon be added

### Spoken Dialog Systems and Conversational Analysis

> Will soon be added

### Speech Coding and Enhancement

> Will soon be added

### Paralinguistics

> Will soon be added

### Speech Enhancement and Denoising

> Will soon be added

### Speech Synthesis: Evaluation

> Will soon be added

### End-to-end Spoken Dialog Systems

> Will soon be added

### Biosignal-enabled Spoken Communication

> Will soon be added

### Neural-based Speech and Acoustic Analysis

> Will soon be added

### DiGo - Dialog for Good: Speech and Language Technology for Social Good

> Will soon be added

### Spoken Language Processing: Translation, Information Retrieval, Summarization, Resources, and Evaluation

> Will soon be added

### Speech, Voice, and Hearing Disorders

> Will soon be added

### Spoken Term Detection and Voice Search

> Will soon be added

### Models for Streaming ASR

> Will soon be added

### Source Separation

> Will soon be added

### Speech Perception

> Will soon be added

### Phonetics and Phonology: Languages and Varieties

> Will soon be added

### Speaker and Language Identification

> Will soon be added

### Speech Synthesis and Voice Conversion

> Will soon be added

### Speech and Language in Health: From Remote Monitoring to Medical Conversations

> Will soon be added

### Novel Transformer Models for ASR

> Will soon be added

### Speaker Recognition

> Will soon be added

### Cross-lingual and Multilingual ASR

> Will soon be added

### Voice Conversion

> Will soon be added

### Pathological Speech Analysis

> Will soon be added

### Multimodal Speech Emotion Recognition

> Will soon be added

### Phonetics, Phonology, and Prosody

> Will soon be added

### Speech Coding: Privacy

> Will soon be added

### Analysis of Neural Speech Representations

> Will soon be added

### End-to-end ASR

> Will soon be added

### Spoken Language Understanding, Summarization, and Information Retrieval

> Will soon be added

### Invariant and Robust Pre-trained Acoustic Models

> Will soon be added

### Speech Synthesis: Representation Learning

> Will soon be added

### Speech Perception, Production, and Acquisition

> Will soon be added

### Acoustic Model Adaptation for ASR

> Will soon be added

### Speech Synthesis: Expressivity

> Will soon be added

### Multi-modal Systems

> Will soon be added

### Question Answering from Speech

> Will soon be added

### Multi-talker Methods in Speech Processing

> Will soon be added

### Sociophonetics

> Will soon be added

### Speaker and Language Diarization

> Will soon be added

### Anti-Spoofing for Speaker Verification

> Will soon be added

### Speech Coding: Intelligibility

> Will soon be added

### Resources for Spoken Language Processing

> Will soon be added

### New Computational Strategies for ASR Training and Inference

> Will soon be added

### MERLIon CCS Challenge: Multilingual Everyday Recordings - Language Identification On Code-Switched Child- Directed Speech

> Will soon be added

### Health-Related Speech Analysis

> Will soon be added

### Automatic Audio Classification and Audio Captioning

> Will soon be added

### Speech Synthesis

> Will soon be added

### Speech Synthesis: Controllability and Adaptation

> Will soon be added

### Search Methods and Decoding Algorithms for ASR

> Will soon be added

### Speech Signal Analysis

> Will soon be added

### Connecting Speech-science and Speech-technology for Children's Speech

> Will soon be added

### Dialog Management

> Will soon be added

### Speech Activity Detection and Modeling

> Will soon be added

### Multilingual Models for ASR

> Will soon be added

### Speech Enhancement and Bandwidth Expansion

> Will soon be added

### Articulation

> Will soon be added

### Neural Processing of Speech and Language: Encoding and Decoding the Diverse Auditory Brain

> Will soon be added

### Perception of Paralinguistics

> Will soon be added

### Technologies for Child Speech Processing

> Will soon be added

### Speech Synthesis: Multilinguality; Evaluation

> Will soon be added
