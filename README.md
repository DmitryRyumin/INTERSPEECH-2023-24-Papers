<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&height=115&color=2C2A2E&text=INTERSPEECH-2024-Papers&section=header&reversal=false&textBg=false&fontAlign=50&fontSize=36&fontColor=FFFFFF&animation=scaleIn&fontAlignY=18" alt="INTERSPEECH-2023-24-Papers">
</p>

<table align="center">
  <tr>
    <td><strong>General Information</strong></td>
    <td>
      <a href="https://github.com/sindresorhus/awesome">
        <img src="https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg" alt="Awesome">
      </a>
      <a href="https://interspeech2024.org/">
        <img src="http://img.shields.io/badge/INTERSPEECH-2024-0C1C43.svg" alt="Conference">
      </a>
      <img src="https://img.shields.io/badge/version-v1.0.0-4FC528" alt="Version">
      <img src="https://img.shields.io/badge/License-MIT-green.svg" alt="License: MIT">
    </td>
  </tr>
  <tr>
    <td><strong>Repository Size and Activity</strong></td>
    <td>
      <img src="https://img.shields.io/github/repo-size/DmitryRyumin/INTERSPEECH-2023-24-Papers" alt="GitHub repo size">
      <img src="https://img.shields.io/github/commit-activity/t/dmitryryumin/INTERSPEECH-2023-24-Papers" alt="GitHub commit activity (branch)">
    </td>
  </tr>
  <tr>
    <td><strong>Contribution Statistics</strong></td>
    <td>
      <img src="https://img.shields.io/github/contributors/dmitryryumin/INTERSPEECH-2023-24-Papers" alt="GitHub contributors">
      <img src="https://img.shields.io/github/issues-closed/DmitryRyumin/INTERSPEECH-2023-24-Papers" alt="GitHub closed issues">
      <img src="https://img.shields.io/github/issues/DmitryRyumin/INTERSPEECH-2023-24-Papers" alt="GitHub issues">
      <img src="https://img.shields.io/github/issues-pr-closed/DmitryRyumin/INTERSPEECH-2023-24-Papers" alt="GitHub closed pull requests">
      <img src="https://img.shields.io/github/issues-pr/dmitryryumin/INTERSPEECH-2023-24-Papers" alt="GitHub pull requests">
    </td>
  </tr>
  <tr>
    <td><strong>Other Metrics</strong></td>
    <td>
      <img src="https://img.shields.io/github/last-commit/DmitryRyumin/INTERSPEECH-2023-24-Papers" alt="GitHub last commit">
      <img src="https://img.shields.io/github/watchers/dmitryryumin/INTERSPEECH-2023-24-Papers?style=flat" alt="GitHub watchers">
      <img src="https://img.shields.io/github/forks/dmitryryumin/INTERSPEECH-2023-24-Papers?style=flat" alt="GitHub forks">
      <img src="https://img.shields.io/github/stars/dmitryryumin/INTERSPEECH-2023-24-Papers?style=flat" alt="GitHub Repo stars">
      <img src="https://api.visitorbadge.io/api/combined?path=https%3A%2F%2Fgithub.com%2FDmitryRyumin%2FINTERSPEECH-2023-Papers&label=Visitors&countColor=%23263759&style=flat" alt="Visitors">
    </td>
  </tr>
  <tr>
    <td><strong>Application</strong></td>
    <td>
      <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
        <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
      </a>
    </td>
  </tr>
  <tr>
    <td colspan="2" align="center"><strong>Progress Status</strong></td>
  </tr>
  <tr>
    <td><strong>Main</strong></td>
    <td>
      <div style="float:left;">
        <img src="https://geps.dev/progress/0?successColor=006600" alt="" />
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/completed_checkmark_done.svg" width="25" alt="" />
      </div>
    </td>
  </tr>
</table>

---

INTERSPEECH 2024 Papers: A complete collection of influential and exciting research papers from the [*INTERSPEECH 2024*](https://interspeech2024.org/) conference. Explore the latest advances in speech and language processing. Code included. :star: the repository to support the advancement of speech technology!

<p align="center">
    <a href="https://interspeech2024.org/" target="_blank">
        <img width="600" src="https://cdn.jsdelivr.net/gh/DmitryRyumin/INTERSPEECH-2023-24-Papers@main/images/Interspeech2024-banner.png" alt="INTERSPEECH 2024">
    </a>
<p>

---

> [!TIP]
[*The PDF version of the INTERSPEECH 2024 Conference Programme*](https://drive.google.com/file/d/1w_F9STjblCMANAZXO8l5Yy6vfDSNYFIw/view), comprises a list of all accepted full papers, their presentation order, as well as the designated presentation times.

---

<a href="https://github.com/DmitryRyumin/NewEraAI-Papers" style="float:left;">
  <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arrow_click_cursor_pointer.png" width="25" alt="" />
  Other collections of the best AI conferences
</a>

<br />
<br />

> [!important]
> Conference table will be up to date all the time.

<table>
    <tr>
        <td rowspan="2" align="center"><strong>Conference</strong></td>
        <td colspan="2" align="center"><strong>Year</strong></td>
    </tr>
    <tr>
        <td colspan="1" align="center"><i>2023</i></td>
        <td colspan="1" align="center"><i>2024</i></td>
    </tr>
    <tr>
        <td colspan="3" align="center"><i>Computer Vision (CV)</i></td>
    </tr>
    <tr>
        <td>CVPR</td>
        <td colspan="2" align="center"><a href="https://github.com/DmitryRyumin/CVPR-2023-24-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/CVPR-2023-24-Papers?style=flat" alt="" /></a></td>
    </tr>
    <tr>
        <td>ICCV</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/ICCV-2023-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/ICCV-2023-Papers?style=flat" alt="" />&nbsp;<img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/done.svg" width="20" alt="" /></a></td>
        <td align="center"><img src="https://img.shields.io/badge/Not%20Scheduled-CC5540" alt=""/></td>
    </tr>
    <tr>
        <td>ECCV</td>
        <td align="center"><img src="https://img.shields.io/badge/Not%20Scheduled-CC5540" alt=""/></td>
        <td align="center"><img src="https://img.shields.io/badge/October-white?logo=github&labelColor=b31b1b" alt="" /></td>
    </tr>
    <tr>
        <td>WACV</td>
        <td align="center">:heavy_minus_sign:</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/WACV-2024-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/WACV-2024-Papers?style=flat" alt="" />&nbsp;<img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/done.svg" width="20" alt="" /></a></td>
    </tr>
    <tr>
        <td>FG</td>
        <td align="center">:heavy_minus_sign:</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/FG-2024-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/FG-2024-Papers?style=flat" alt="" /></a></td>
    </tr>
    <tr>
        <td colspan="3" align="center"><i>Speech/Signal Processing (SP/SigProc)</i></td>
    </tr>
    <tr>
        <td>ICASSP</td>
        <td colspan="2" align="center"><a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/ICASSP-2023-24-Papers?style=flat" alt="" /></a></td>
    </tr>
    <tr>
        <td>INTERSPEECH</td>
        <td colspan="2" align="center"><a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/INTERSPEECH-2023-24-Papers?style=flat" alt="" /></a></td>
    </tr>
    <tr>
        <td>ISMIR</td>
        <td align="center"><a href="https://github.com/yamathcy/ISMIR-2023-Papers" target="_blank"><img src="https://img.shields.io/github/stars/yamathcy/ISMIR-2023-Papers?style=flat" alt="" />&nbsp;<img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/done.svg" width="20" alt="" /></a></td>
        <td align="center">:heavy_minus_sign:</td>
    </tr>
    <tr>
        <td colspan="3" align="center"><i>Natural Language Processing (NLP)</i></td>
    </tr>
    <tr>
        <td>EMNLP</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/EMNLP-2023-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/EMNLP-2023-Papers?style=flat" alt="" /></a></td>
        <td align="center"><img src="https://img.shields.io/badge/December-white?logo=github&labelColor=b31b1b" alt="" /></td>
    </tr>
    <tr>
        <td colspan="3" align="center"><i>Machine Learning (ML)</i></td>
    </tr>
    <tr>
        <td>AAAI</td>
        <td align="center">:heavy_minus_sign:</td>
        <td align="center"><a href="https://github.com/DmitryRyumin/AAAI-2024-Papers" target="_blank"><img src="https://img.shields.io/github/stars/DmitryRyumin/AAAI-2024-Papers?style=flat" alt="" /></a></td>
    </tr>
    <tr>
        <td>ICLR</td>
        <td align="center">:heavy_minus_sign:</td>
        <td align="center"><img src="https://img.shields.io/badge/May-white?logo=github&labelColor=b31b1b" alt="" /></td>
    </tr>
    <tr>
        <td>ICML</td>
        <td align="center">:heavy_minus_sign:</td>
        <td align="center"><img src="https://img.shields.io/badge/July-white?logo=github&labelColor=b31b1b" alt="" /></td>
    </tr>
    <tr>
        <td>NeurIPS</td>
        <td align="center">:heavy_minus_sign:</td>
        <td align="center"><img src="https://img.shields.io/badge/December-white?logo=github&labelColor=b31b1b" alt="" /></td>
    </tr>
</table>

---

## Contributors

<a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/graphs/contributors">
  <img src="http://contributors.nn.ci/api?repo=DmitryRyumin/INTERSPEECH-2023-24-Papers" alt="" />
</a>

<br />
<br />

> [!NOTE]
> Contributions to improve the completeness of this list are greatly appreciated. If you come across any overlooked papers, please **feel free to [*create pull requests*](https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/pulls), [*open issues*](https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/issues) or contact me via [*email*](mailto:neweraairesearch@gmail.com)**. Your participation is crucial to making this repository even better.

---

## [Papers-2024](https://www.isca-archive.org/interspeech_2024/) <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/ai.svg" width="30" alt="" />

<a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
  <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
</a>

<table>
    <thead>
        <tr>
            <th scope="col">Section</th>
            <th scope="col">Papers</th>
            <th scope="col"><img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /></th>
            <th scope="col"><img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /></th>
            <th scope="col"><img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/video.svg" width="27" alt="" /></th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2024/main/l2-speech-bilingualism-and-code-switching.md">L2 Speech, Bilingualism and Code-Switching</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2024/main/l2-speech-bilingualism-and-code-switching.md"><img src="https://img.shields.io/badge/4-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2024/main/l2-speech-bilingualism-and-code-switching.md"><img src="https://img.shields.io/badge/0-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2024/main/l2-speech-bilingualism-and-code-switching.md"><img src="https://img.shields.io/badge/0-1D7FBF" alt="Open Code"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2024/main/l2-speech-bilingualism-and-code-switching.md"><img src="https://img.shields.io/badge/0-FF0000" alt="Videos"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2024/main/speaker-diarization.md">Speaker Diarization</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2024/main/speaker-diarization.md"><img src="https://img.shields.io/badge/12-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2024/main/speaker-diarization.md"><img src="https://img.shields.io/badge/7-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2024/main/speaker-diarization.md"><img src="https://img.shields.io/badge/2-1D7FBF" alt="Open Code"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2024/main/speaker-diarization.md"><img src="https://img.shields.io/badge/1-FF0000" alt="Videos"></a>
            </td>
        </tr>
    </tbody>
</table>

---

## [Papers-2023](https://www.isca-archive.org/interspeech_2023/) <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/ai.svg" width="30" alt="" />

<a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
  <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
</a>

<table>
    <thead>
        <tr>
            <th scope="col">Section</th>
            <th scope="col">Papers</th>
            <th scope="col"><img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/arxiv-logo.svg" width="45" alt="" /></th>
            <th scope="col"><img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/github_code_developer.svg" width="27" alt="" /></th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/resources-for-spoken-language-processing.md">Resources for Spoken Language Processing</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/resources-for-spoken-language-processing.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/resources-for-spoken-language-processing.md"><img src="https://img.shields.io/badge/3-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/resources-for-spoken-language-processing.md"><img src="https://img.shields.io/badge/2-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-prosody-and-emotion.md">Speech Synthesis: Prosody and Emotion</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-prosody-and-emotion.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-prosody-and-emotion.md"><img src="https://img.shields.io/badge/4-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-prosody-and-emotion.md"><img src="https://img.shields.io/badge/2-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/statistical-machine-translation.md">Statistical Machine Translation</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/statistical-machine-translation.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/statistical-machine-translation.md"><img src="https://img.shields.io/badge/4-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/statistical-machine-translation.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/self-supervised-learning-in-asr.md">Self-Supervised Learning in ASR</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/self-supervised-learning-in-asr.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/self-supervised-learning-in-asr.md"><img src="https://img.shields.io/badge/4-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/self-supervised-learning-in-asr.md"><img src="https://img.shields.io/badge/3-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/prosody.md">Prosody</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/prosody.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/prosody.md"><img src="https://img.shields.io/badge/0-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/prosody.md"><img src="https://img.shields.io/badge/0-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-production.md">Speech Production</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-production.md"><img src="https://img.shields.io/badge/4-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-production.md"><img src="https://img.shields.io/badge/1-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-production.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/dysarthric-speech-assessment.md">Dysarthric Speech Assessment</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/dysarthric-speech-assessment.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/dysarthric-speech-assessment.md"><img src="https://img.shields.io/badge/4-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/dysarthric-speech-assessment.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-coding-transmission.md">Speech Coding: Transmission</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-coding-transmission.md"><img src="https://img.shields.io/badge/4-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-coding-transmission.md"><img src="https://img.shields.io/badge/0-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-coding-transmission.md"><img src="https://img.shields.io/badge/2-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-recognition-signal-processing-acoustic-modeling-robustness-adaptation.md">Speech Recognition: Signal Processing, Acoustic Modeling, Robustness, Adaptation</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-recognition-signal-processing-acoustic-modeling-robustness-adaptation.md"><img src="https://img.shields.io/badge/75-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-recognition-signal-processing-acoustic-modeling-robustness-adaptation.md"><img src="https://img.shields.io/badge/48-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-recognition-signal-processing-acoustic-modeling-robustness-adaptation.md"><img src="https://img.shields.io/badge/17-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/analysis-of-speech-and-audio-signals.md">Analysis of Speech and Audio Signals</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/analysis-of-speech-and-audio-signals.md"><img src="https://img.shields.io/badge/85-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/analysis-of-speech-and-audio-signals.md"><img src="https://img.shields.io/badge/32-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/analysis-of-speech-and-audio-signals.md"><img src="https://img.shields.io/badge/27-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-recognition-architecture-search-and-linguistic-components.md">Speech Recognition: Architecture, Search, and Linguistic Components</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-recognition-architecture-search-and-linguistic-components.md"><img src="https://img.shields.io/badge/50-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-recognition-architecture-search-and-linguistic-components.md"><img src="https://img.shields.io/badge/26-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-recognition-architecture-search-and-linguistic-components.md"><img src="https://img.shields.io/badge/6-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-recognition-technologies-and-systems-for-new-applications.md">Speech Recognition: Technologies and Systems for New Applications</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-recognition-technologies-and-systems-for-new-applications.md"><img src="https://img.shields.io/badge/35-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-recognition-technologies-and-systems-for-new-applications.md"><img src="https://img.shields.io/badge/20-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-recognition-technologies-and-systems-for-new-applications.md"><img src="https://img.shields.io/badge/8-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/lexical-and-language-modeling-for-asr.md">Lexical and Language Modeling for ASR</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/lexical-and-language-modeling-for-asr.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/lexical-and-language-modeling-for-asr.md"><img src="https://img.shields.io/badge/5-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/lexical-and-language-modeling-for-asr.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/language-identification-and-diarization.md">Language Identification and Diarization</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/language-identification-and-diarization.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/language-identification-and-diarization.md"><img src="https://img.shields.io/badge/1-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/language-identification-and-diarization.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-quality-assessment.md">Speech Quality Assessment</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-quality-assessment.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-quality-assessment.md"><img src="https://img.shields.io/badge/0-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-quality-assessment.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/feature-modeling-for-asr.md">Feature Modeling for ASR</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/feature-modeling-for-asr.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/feature-modeling-for-asr.md"><img src="https://img.shields.io/badge/3-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/feature-modeling-for-asr.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/interfacing-speech-technology-and-phonetics.md">Interfacing Speech Technology and Phonetics</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/interfacing-speech-technology-and-phonetics.md"><img src="https://img.shields.io/badge/4-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/interfacing-speech-technology-and-phonetics.md"><img src="https://img.shields.io/badge/0-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/interfacing-speech-technology-and-phonetics.md"><img src="https://img.shields.io/badge/0-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-multilinguality.md">Speech Synthesis: Multilinguality</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-multilinguality.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-multilinguality.md"><img src="https://img.shields.io/badge/5-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-multilinguality.md"><img src="https://img.shields.io/badge/0-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-emotion-recognition.md">Speech Emotion Recognition</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-emotion-recognition.md"><img src="https://img.shields.io/badge/29-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-emotion-recognition.md"><img src="https://img.shields.io/badge/6-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-emotion-recognition.md"><img src="https://img.shields.io/badge/5-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/spoken-dialog-systems-and-conversational-analysis.md">Spoken Dialog Systems and Conversational Analysis</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/spoken-dialog-systems-and-conversational-analysis.md"><img src="https://img.shields.io/badge/37-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/spoken-dialog-systems-and-conversational-analysis.md"><img src="https://img.shields.io/badge/8-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/spoken-dialog-systems-and-conversational-analysis.md"><img src="https://img.shields.io/badge/4-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-coding-and-enhancement.md">Speech Coding and Enhancement</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-coding-and-enhancement.md"><img src="https://img.shields.io/badge/58-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-coding-and-enhancement.md"><img src="https://img.shields.io/badge/33-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-coding-and-enhancement.md"><img src="https://img.shields.io/badge/14-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/paralinguistics.md">Paralinguistics</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/paralinguistics.md"><img src="https://img.shields.io/badge/22-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/paralinguistics.md"><img src="https://img.shields.io/badge/8-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/paralinguistics.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-enhancement-and-denoising.md">Speech Enhancement and Denoising</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-enhancement-and-denoising.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-enhancement-and-denoising.md"><img src="https://img.shields.io/badge/3-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-enhancement-and-denoising.md"><img src="https://img.shields.io/badge/0-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-evaluation.md">Speech Synthesis: Evaluation</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-evaluation.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-evaluation.md"><img src="https://img.shields.io/badge/2-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-evaluation.md"><img src="https://img.shields.io/badge/0-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/end-to-end-spoken-dialog-systems.md">End-to-End Spoken Dialog Systems</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/end-to-end-spoken-dialog-systems.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/end-to-end-spoken-dialog-systems.md"><img src="https://img.shields.io/badge/2-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/end-to-end-spoken-dialog-systems.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/biosignal-enabled-spoken-communication.md">Biosignal-enabled Spoken Communication</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/biosignal-enabled-spoken-communication.md"><img src="https://img.shields.io/badge/10-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/biosignal-enabled-spoken-communication.md"><img src="https://img.shields.io/badge/2-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/biosignal-enabled-spoken-communication.md"><img src="https://img.shields.io/badge/3-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/neural-based-speech-and-acoustic-analysis.md">Neural-based Speech and Acoustic Analysis</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/neural-based-speech-and-acoustic-analysis.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/neural-based-speech-and-acoustic-analysis.md"><img src="https://img.shields.io/badge/5-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/neural-based-speech-and-acoustic-analysis.md"><img src="https://img.shields.io/badge/3-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/digo---dialog-for-good-speech-and-language-technology-for-social-good.md">DiGo - Dialog for Good: Speech and Language Technology for Social Good</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/digo---dialog-for-good-speech-and-language-technology-for-social-good.md"><img src="https://img.shields.io/badge/5-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/digo---dialog-for-good-speech-and-language-technology-for-social-good.md"><img src="https://img.shields.io/badge/3-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/digo---dialog-for-good-speech-and-language-technology-for-social-good.md"><img src="https://img.shields.io/badge/2-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/spoken-language-processing-translation-information-retrieval-summarization-resources-and-evaluation.md">Spoken Language Processing: Translation, Information Retrieval, Summarization, Resources, and Evaluation</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/spoken-language-processing-translation-information-retrieval-summarization-resources-and-evaluation.md"><img src="https://img.shields.io/badge/48-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/spoken-language-processing-translation-information-retrieval-summarization-resources-and-evaluation.md"><img src="https://img.shields.io/badge/21-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/spoken-language-processing-translation-information-retrieval-summarization-resources-and-evaluation.md"><img src="https://img.shields.io/badge/13-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-voice-and-hearing-disorders.md">Speech, Voice, and Hearing Disorders</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-voice-and-hearing-disorders.md"><img src="https://img.shields.io/badge/28-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-voice-and-hearing-disorders.md"><img src="https://img.shields.io/badge/13-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-voice-and-hearing-disorders.md"><img src="https://img.shields.io/badge/6-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/spoken-term-detection-and-voice-search.md">Spoken Term Detection and Voice Search</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/spoken-term-detection-and-voice-search.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/spoken-term-detection-and-voice-search.md"><img src="https://img.shields.io/badge/3-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/spoken-term-detection-and-voice-search.md"><img src="https://img.shields.io/badge/0-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/models-for-streaming-asr.md">Models for Streaming ASR</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/models-for-streaming-asr.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/models-for-streaming-asr.md"><img src="https://img.shields.io/badge/5-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/models-for-streaming-asr.md"><img src="https://img.shields.io/badge/0-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/source-separation.md">Source Separation</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/source-separation.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/source-separation.md"><img src="https://img.shields.io/badge/2-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/source-separation.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-perception.md">Speech Perception</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-perception.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-perception.md"><img src="https://img.shields.io/badge/0-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-perception.md"><img src="https://img.shields.io/badge/0-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/phonetics-and-phonology-languages-and-varieties.md">Phonetics and Phonology: Languages and Varieties</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/phonetics-and-phonology-languages-and-varieties.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/phonetics-and-phonology-languages-and-varieties.md"><img src="https://img.shields.io/badge/0-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/phonetics-and-phonology-languages-and-varieties.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speaker-and-language-identification.md">Speaker and Language Identification</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speaker-and-language-identification.md"><img src="https://img.shields.io/badge/59-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speaker-and-language-identification.md"><img src="https://img.shields.io/badge/30-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speaker-and-language-identification.md"><img src="https://img.shields.io/badge/16-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-and-voice-conversion.md">Speech Synthesis and Voice Conversion</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-and-voice-conversion.md"><img src="https://img.shields.io/badge/17-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-and-voice-conversion.md"><img src="https://img.shields.io/badge/7-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-and-voice-conversion.md"><img src="https://img.shields.io/badge/4-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-and-language-in-health-from-remote-monitoring-to-medical-conversations.md">Speech and Language in Health: from Remote Monitoring to Medical Conversations</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-and-language-in-health-from-remote-monitoring-to-medical-conversations.md"><img src="https://img.shields.io/badge/29-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-and-language-in-health-from-remote-monitoring-to-medical-conversations.md"><img src="https://img.shields.io/badge/13-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-and-language-in-health-from-remote-monitoring-to-medical-conversations.md"><img src="https://img.shields.io/badge/6-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/novel-transformer-models-for-asr.md">Novel Transformer Models for ASR</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/novel-transformer-models-for-asr.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/novel-transformer-models-for-asr.md"><img src="https://img.shields.io/badge/4-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/novel-transformer-models-for-asr.md"><img src="https://img.shields.io/badge/2-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speaker-recognition.md">Speaker Recognition</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speaker-recognition.md"><img src="https://img.shields.io/badge/10-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speaker-recognition.md"><img src="https://img.shields.io/badge/7-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speaker-recognition.md"><img src="https://img.shields.io/badge/2-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/cross-lingual-and-multilingual-asr.md">Cross-lingual and Multilingual ASR</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/cross-lingual-and-multilingual-asr.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/cross-lingual-and-multilingual-asr.md"><img src="https://img.shields.io/badge/4-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/cross-lingual-and-multilingual-asr.md"><img src="https://img.shields.io/badge/2-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/voice-conversion.md">Voice Conversion</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/voice-conversion.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/voice-conversion.md"><img src="https://img.shields.io/badge/2-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/voice-conversion.md"><img src="https://img.shields.io/badge/3-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/pathological-speech-analysis.md">Pathological Speech Analysis</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/pathological-speech-analysis.md"><img src="https://img.shields.io/badge/12-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/pathological-speech-analysis.md"><img src="https://img.shields.io/badge/1-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/pathological-speech-analysis.md"><img src="https://img.shields.io/badge/2-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/multimodal-speech-emotion-recognition.md">Multimodal Speech Emotion Recognition</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/multimodal-speech-emotion-recognition.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/multimodal-speech-emotion-recognition.md"><img src="https://img.shields.io/badge/0-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/multimodal-speech-emotion-recognition.md"><img src="https://img.shields.io/badge/0-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/phonetics-phonology-and-prosody.md">Phonetics, Phonology, and Prosody</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/phonetics-phonology-and-prosody.md"><img src="https://img.shields.io/badge/32-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/phonetics-phonology-and-prosody.md"><img src="https://img.shields.io/badge/4-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/phonetics-phonology-and-prosody.md"><img src="https://img.shields.io/badge/3-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-coding-privacy.md">Speech Coding: Privacy</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-coding-privacy.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-coding-privacy.md"><img src="https://img.shields.io/badge/4-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-coding-privacy.md"><img src="https://img.shields.io/badge/2-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/analysis-of-neural-speech-representations.md">Analysis of Neural Speech Representations</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/analysis-of-neural-speech-representations.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/analysis-of-neural-speech-representations.md"><img src="https://img.shields.io/badge/3-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/analysis-of-neural-speech-representations.md"><img src="https://img.shields.io/badge/3-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/end-to-end-asr.md">End-to-end ASR</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/end-to-end-asr.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/end-to-end-asr.md"><img src="https://img.shields.io/badge/5-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/end-to-end-asr.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/spoken-language-understanding-summarization-and-information-retrieval.md">Spoken Language Understanding, Summarization, and Information Retrieval</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/spoken-language-understanding-summarization-and-information-retrieval.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/spoken-language-understanding-summarization-and-information-retrieval.md"><img src="https://img.shields.io/badge/3-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/spoken-language-understanding-summarization-and-information-retrieval.md"><img src="https://img.shields.io/badge/4-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/invariant-and-robust-pre-trained-acoustic-models.md">Invariant and Robust Pre-trained Acoustic Models</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/invariant-and-robust-pre-trained-acoustic-models.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/invariant-and-robust-pre-trained-acoustic-models.md"><img src="https://img.shields.io/badge/5-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/invariant-and-robust-pre-trained-acoustic-models.md"><img src="https://img.shields.io/badge/3-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-representation-learning.md">Speech Synthesis: Representation Learning</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-representation-learning.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-representation-learning.md"><img src="https://img.shields.io/badge/3-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-representation-learning.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-perception-production-and-acquisition.md">Speech Perception, Production, and Acquisition</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-perception-production-and-acquisition.md"><img src="https://img.shields.io/badge/33-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-perception-production-and-acquisition.md"><img src="https://img.shields.io/badge/4-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-perception-production-and-acquisition.md"><img src="https://img.shields.io/badge/3-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/acoustic-model-adaptation-for-asr.md">Acoustic Model Adaptation for ASR</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/acoustic-model-adaptation-for-asr.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/acoustic-model-adaptation-for-asr.md"><img src="https://img.shields.io/badge/6-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/acoustic-model-adaptation-for-asr.md"><img src="https://img.shields.io/badge/3-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-expressivity.md">Speech Synthesis: Expressivity</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-expressivity.md"><img src="https://img.shields.io/badge/26-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-expressivity.md"><img src="https://img.shields.io/badge/15-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-expressivity.md"><img src="https://img.shields.io/badge/4-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/multi-modal-systems.md">Multi-modal Systems</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/multi-modal-systems.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/multi-modal-systems.md"><img src="https://img.shields.io/badge/4-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/multi-modal-systems.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/question-answering-from-speech.md">Question Answering from Speech</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/question-answering-from-speech.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/question-answering-from-speech.md"><img src="https://img.shields.io/badge/2-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/question-answering-from-speech.md"><img src="https://img.shields.io/badge/2-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/multi-talker-methods-in-speech-processing.md">Multi-talker Methods in Speech Processing</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/multi-talker-methods-in-speech-processing.md"><img src="https://img.shields.io/badge/16-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/multi-talker-methods-in-speech-processing.md"><img src="https://img.shields.io/badge/7-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/multi-talker-methods-in-speech-processing.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/sociophonetics.md">Sociophonetics</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/sociophonetics.md"><img src="https://img.shields.io/badge/4-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/sociophonetics.md"><img src="https://img.shields.io/badge/0-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/sociophonetics.md"><img src="https://img.shields.io/badge/0-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speaker-and-language-diarization.md">Speaker and Language Diarization</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speaker-and-language-diarization.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speaker-and-language-diarization.md"><img src="https://img.shields.io/badge/3-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speaker-and-language-diarization.md"><img src="https://img.shields.io/badge/0-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/anti-spoofing-for-speaker-verification.md">Anti-Spoofing for Speaker Verification</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/anti-spoofing-for-speaker-verification.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/anti-spoofing-for-speaker-verification.md"><img src="https://img.shields.io/badge/4-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/anti-spoofing-for-speaker-verification.md"><img src="https://img.shields.io/badge/3-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-coding-intelligibility.md">Speech Coding: Intelligibility</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-coding-intelligibility.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-coding-intelligibility.md"><img src="https://img.shields.io/badge/3-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-coding-intelligibility.md"><img src="https://img.shields.io/badge/0-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/new-computational-strategies-for-asr-training-and-inference.md">New Computational Strategies for ASR Training and Inference</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/new-computational-strategies-for-asr-training-and-inference.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/new-computational-strategies-for-asr-training-and-inference.md"><img src="https://img.shields.io/badge/4-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/new-computational-strategies-for-asr-training-and-inference.md"><img src="https://img.shields.io/badge/0-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/merlion-ccs-challenge-multilingual-everyday-recordings---language-identification-on-code-switched-child-directed-speech.md">MERLIon CCS Challenge: Multilingual Everyday Recordings - Language Identification On Code-Switched Child-Directed Speech</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/merlion-ccs-challenge-multilingual-everyday-recordings---language-identification-on-code-switched-child-directed-speech.md"><img src="https://img.shields.io/badge/5-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/merlion-ccs-challenge-multilingual-everyday-recordings---language-identification-on-code-switched-child-directed-speech.md"><img src="https://img.shields.io/badge/3-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/merlion-ccs-challenge-multilingual-everyday-recordings---language-identification-on-code-switched-child-directed-speech.md"><img src="https://img.shields.io/badge/2-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/health-related-speech-analysis.md">Health-Related Speech Analysis</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/health-related-speech-analysis.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/health-related-speech-analysis.md"><img src="https://img.shields.io/badge/0-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/health-related-speech-analysis.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/automatic-audio-classification-and-audio-captioning.md">Automatic Audio Classification and Audio Captioning</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/automatic-audio-classification-and-audio-captioning.md"><img src="https://img.shields.io/badge/4-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/automatic-audio-classification-and-audio-captioning.md"><img src="https://img.shields.io/badge/4-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/automatic-audio-classification-and-audio-captioning.md"><img src="https://img.shields.io/badge/2-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis.md">Speech Synthesis</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis.md"><img src="https://img.shields.io/badge/22-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis.md"><img src="https://img.shields.io/badge/11-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis.md"><img src="https://img.shields.io/badge/7-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-controllability-and-adaptation.md">Speech Synthesis: Controllability and Adaptation</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-controllability-and-adaptation.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-controllability-and-adaptation.md"><img src="https://img.shields.io/badge/2-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-controllability-and-adaptation.md"><img src="https://img.shields.io/badge/2-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/search-methods-and-decoding-algorithms-for-asr.md">Search Methods and Decoding Algorithms for ASR</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/search-methods-and-decoding-algorithms-for-asr.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/search-methods-and-decoding-algorithms-for-asr.md"><img src="https://img.shields.io/badge/3-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/search-methods-and-decoding-algorithms-for-asr.md"><img src="https://img.shields.io/badge/2-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-signal-analysis.md">Speech Signal Analysis</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-signal-analysis.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-signal-analysis.md"><img src="https://img.shields.io/badge/4-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-signal-analysis.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/connecting-speech-science-and-speech-technology-for-childrens-speech.md">Connecting Speech-science and Speech-technology for Children's Speech</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/connecting-speech-science-and-speech-technology-for-childrens-speech.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/connecting-speech-science-and-speech-technology-for-childrens-speech.md"><img src="https://img.shields.io/badge/4-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/connecting-speech-science-and-speech-technology-for-childrens-speech.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/dialog-management.md">Dialog Management</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/dialog-management.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/dialog-management.md"><img src="https://img.shields.io/badge/4-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/dialog-management.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-activity-detection-and-modeling.md">Speech Activity Detection and Modeling</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-activity-detection-and-modeling.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-activity-detection-and-modeling.md"><img src="https://img.shields.io/badge/3-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-activity-detection-and-modeling.md"><img src="https://img.shields.io/badge/0-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/multilingual-models-for-asr.md">Multilingual Models for ASR</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/multilingual-models-for-asr.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/multilingual-models-for-asr.md"><img src="https://img.shields.io/badge/4-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/multilingual-models-for-asr.md"><img src="https://img.shields.io/badge/2-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-enhancement-and-bandwidth-expansion.md">Speech Enhancement and Bandwidth Expansion</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-enhancement-and-bandwidth-expansion.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-enhancement-and-bandwidth-expansion.md"><img src="https://img.shields.io/badge/2-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-enhancement-and-bandwidth-expansion.md"><img src="https://img.shields.io/badge/2-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/articulation.md">Articulation</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/articulation.md"><img src="https://img.shields.io/badge/4-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/articulation.md"><img src="https://img.shields.io/badge/2-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/articulation.md"><img src="https://img.shields.io/badge/3-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/neural-processing-of-speech-and-language-encoding-and-decoding-the-diverse-auditory-brain.md">Neural Processing of Speech and Language: Encoding and Decoding the Diverse Auditory Brain</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/neural-processing-of-speech-and-language-encoding-and-decoding-the-diverse-auditory-brain.md"><img src="https://img.shields.io/badge/9-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/neural-processing-of-speech-and-language-encoding-and-decoding-the-diverse-auditory-brain.md"><img src="https://img.shields.io/badge/3-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/neural-processing-of-speech-and-language-encoding-and-decoding-the-diverse-auditory-brain.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/perception-of-paralinguistics.md">Perception of Paralinguistics</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/perception-of-paralinguistics.md"><img src="https://img.shields.io/badge/6-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/perception-of-paralinguistics.md"><img src="https://img.shields.io/badge/1-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/perception-of-paralinguistics.md"><img src="https://img.shields.io/badge/0-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/technologies-for-child-speech-processing.md">Technologies for Child Speech Processing</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/technologies-for-child-speech-processing.md"><img src="https://img.shields.io/badge/4-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/technologies-for-child-speech-processing.md"><img src="https://img.shields.io/badge/2-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/technologies-for-child-speech-processing.md"><img src="https://img.shields.io/badge/2-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-multilinguality-evaluation.md">Speech Synthesis: Multilinguality; Evaluation</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-multilinguality-evaluation.md"><img src="https://img.shields.io/badge/22-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-multilinguality-evaluation.md"><img src="https://img.shields.io/badge/15-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/speech-synthesis-multilinguality-evaluation.md"><img src="https://img.shields.io/badge/7-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/show-and-tell-health-applications-and-emotion-recognition.md">Show and Tell: Health Applications and Emotion Recognition</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/show-and-tell-health-applications-and-emotion-recognition.md"><img src="https://img.shields.io/badge/12-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/show-and-tell-health-applications-and-emotion-recognition.md"><img src="https://img.shields.io/badge/1-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/show-and-tell-health-applications-and-emotion-recognition.md"><img src="https://img.shields.io/badge/0-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/show-and-tell-speech-tools-speech-enhancement-speech-synthesis.md">Show and Tell: Speech Tools, Speech Enhancement, Speech Synthesis</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/show-and-tell-speech-tools-speech-enhancement-speech-synthesis.md"><img src="https://img.shields.io/badge/10-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/show-and-tell-speech-tools-speech-enhancement-speech-synthesis.md"><img src="https://img.shields.io/badge/2-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/show-and-tell-speech-tools-speech-enhancement-speech-synthesis.md"><img src="https://img.shields.io/badge/4-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/show-and-tell-language-learning-and-educational-resources.md">Show and Tell: Language Learning and Educational Resources</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/show-and-tell-language-learning-and-educational-resources.md"><img src="https://img.shields.io/badge/11-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/show-and-tell-language-learning-and-educational-resources.md"><img src="https://img.shields.io/badge/4-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/show-and-tell-language-learning-and-educational-resources.md"><img src="https://img.shields.io/badge/1-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
        <tr>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/show-and-tell-media-and-commercial-applications.md">Show and Tell: Media and Commercial Applications</a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/show-and-tell-media-and-commercial-applications.md"><img src="https://img.shields.io/badge/12-42BA16" alt="Papers"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/show-and-tell-media-and-commercial-applications.md"><img src="https://img.shields.io/badge/2-b31b1b" alt="Preprints"></a>
            </td>
            <td>
                <a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-24-Papers/blob/main/sections/2023/main/show-and-tell-media-and-commercial-applications.md"><img src="https://img.shields.io/badge/2-1D7FBF" alt="Open Code"></a>
            </td>
        </tr>
    </tbody>
</table>

---

## Key Terms

> To be added soon

---

## Star History

<p align="center">
    <a href="https://star-history.com/#Dmitryryumin/Interspeech-2023-papers&Date" target="_blank">
        <img width="500" src="https://api.star-history.com/svg?repos=Dmitryryumin/Interspeech-2023-papers&type=Date" alt="Star History Chart">
    </a>
<p>
