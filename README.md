# INTERSPEECH-2023-Papers

![GitHub repo size](https://img.shields.io/github/repo-size/DmitryRyumin/INTERSPEECH-2023-Papers)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers/blob/main/LICENSE)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers/blob/main/README.md)
![GitHub last commit](https://img.shields.io/github/last-commit/DmitryRyumin/INTERSPEECH-2023-Papers)
<!-- ![Papers Implemented](https://badgen.net/badge/Papers%20implemented/0) -->

---
INTERSPEECH 2023 Papers: A complete collection of influential and exciting research papers from the [*INTERSPEECH 2023*](https://interspeech2023.org/) conference. Explore the latest advances in speech and language processing. Code included. Star the repository to support the advancement of speech technology!

<p align="center">
    <a href="https://interspeech2023.org/" target="_blank">
        <img width="400" src="https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers/blob/main/images/Interspeech2023-Stacked-Colour.png" alt="Interspeech 2023">
    </a>
<p>

---

Contributions to improve the completeness of this list are greatly appreciated. If you come across any overlooked papers, please **feel free to [*create pull requests*](https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers/pulls), [*open issues*](https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers/issues) or contact me via [*email*](mailto:ryumin.d@iias.spb.su)**. Your participation is crucial to making this repository even better.

---

## Papers

### Speech Synthesis: Prosody and Emotion

| **No** | **Title** | **Repo** | **Paper** |
| ------ | --------- |:--------:|:---------:|
| 1 | Emotional Talking Head Generation based on Memory-Sharing and Attention-Augmented Networks | `-` | [![arXiv](https://img.shields.io/badge/arXiv-2306.03594-b31b1b.svg)](https://arxiv.org/abs/2306.03594) |
| 2 | Speech Synthesis with Self-Supervisedly Learnt Prosodic Representations | `-` | `-` |
| 3 | EmoMix: Emotion Mixing via Diffusion Models for Emotional Speech Synthesis | `-` | [![arXiv](https://img.shields.io/badge/arXiv-2306.00648-b31b1b.svg)](https://arxiv.org/abs/2306.00648) |
| 4 | Laughter Synthesis using Pseudo Phonetic Tokens with a Large-scale In-the-wild Laughter Corpus | [![GitHub](https://img.shields.io/github/stars/Aria-K-Alethia/laughter-synthesis)](https://github.com/Aria-K-Alethia/laughter-synthesis) | [![arXiv](https://img.shields.io/badge/arXiv-2305.12442-b31b1b.svg)](https://arxiv.org/abs/2305.12442) |
| 5 | Explicit Intensity Control for Accented Text-to-speech | [![GitHub](https://img.shields.io/github/stars/ttslr/Ai-TTS)](https://github.com/ttslr/Ai-TTS) | [![arXiv](https://img.shields.io/badge/arXiv-2210.15364-b31b1b.svg)](https://arxiv.org/abs/2210.15364) |
| 6 | Comparing Normalizing Flows and Diffusion Models for Prosody and Acoustic Modelling in Text-to-speech | `-` | `-` |

### Statistical Machine Translation

| **No** | **Title** | **Repo** | **Paper** |
| ------ | --------- |:--------:|:---------:|
| 7 | Modular Speech-to-Text Translation for Zero-Shot Cross-Modal Transfer | `-` | `-` |
| 8 | Improving Isochronous Machine Translation with Target Factors and Auxiliary Counters | `-` | [![arXiv](https://img.shields.io/badge/arXiv-2305.13204-b31b1b.svg)](https://arxiv.org/abs/2305.13204) |
| 9 | StyleS2ST: Zero-shot Style Transfer for Direct Speech-to-speech Translation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://styles2st.github.io/StyleS2ST/) | [![arXiv](https://img.shields.io/badge/arXiv-2305.17732-b31b1b.svg)](https://arxiv.org/abs/2305.17732) |
| 10 | Joint Speech Translation and Named Entity Recognition | [![GitHub](https://img.shields.io/github/stars/hlt-mt/FBK-fairseq)](https://github.com/hlt-mt/FBK-fairseq/blob/master/fbk_works/JOINT_ST_NER2023.md) | [![arXiv](https://img.shields.io/badge/arXiv-2210.11987-b31b1b.svg)](https://arxiv.org/abs/2210.11987) |
| 11 | Analysis of Acoustic information in End-to-End Spoken Language Translation | `-` | `-` |
| 12 | LAMASSU: A Streaming Language-Agnostic Multilingual Speech Recognition and Translation Model Using Neural Transducers | `-` | [![arXiv](https://img.shields.io/badge/arXiv-2211.02809-b31b1b.svg)](https://arxiv.org/abs/2211.02809) |

### Self-Supervised Learning in ASR

| **No** | **Title** | **Repo** | **Paper** |
| ------ | --------- |:--------:|:---------:|
| 13 | DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models | [![GitHub](https://img.shields.io/github/stars/pyf98/DPHuBERT)](https://github.com/pyf98/DPHuBERT) | [![arXiv](https://img.shields.io/badge/arXiv-2305.17651-b31b1b.svg)](https://arxiv.org/abs/2305.17651) |
| 14 | Automatic Data Augmentation for Domain Adapted Fine-Tuning of Self-Supervised Speech Representations | [![GitHub](https://img.shields.io/github/stars/salah-zaiem/augmentations_adaptation)](https://github.com/salah-zaiem/augmentations_adaptation) | [![arXiv](https://img.shields.io/badge/arXiv-2306.00481-b31b1b.svg)](https://arxiv.org/abs/2306.00481) |
| 15 | Dual Acoustic Linguistic Self-supervised Representation Learning for Cross-Domain Speech Recognition | `-` | `-` |
| 16 | O-1: Self-training with Oracle and 1-best Hypothesis | `-` | `-` |
| 17 | MT4SSL: Boosting Self-Supervised Speech Representation Learning by Integrating Multiple Targets | [![GitHub](https://img.shields.io/github/stars/ddlBoJack/MT4SSL)](https://github.com/ddlBoJack/MT4SSL) | [![arXiv](https://img.shields.io/badge/arXiv-2211.07321-b31b1b.svg)](https://arxiv.org/abs/2211.07321) |
| 18 | Comparison of Multilingual Self-Supervised and Weakly-Supervised Speech Pre-Training for Adaptation to Unseen Languages | `-` | [![arXiv](https://img.shields.io/badge/arXiv-2305.12606-b31b1b.svg)](https://arxiv.org/abs/2305.12606) |

### Prosody

| **No** | **Title** | **Repo** | **Paper** |
| ------ | --------- |:--------:|:---------:|
| 19 | Chinese EFL Learners' Perception of English Prosodic Focus | `-` | `-` |
| 20 | Pitch Accent Variation and the Interpretation of Rising and Falling Intonation in American English | `-` | `-` |
| 21 | Tonal Coarticulation as a Cue for Upcoming Prosodic Boundary | `-` | `-` |
| 22 | Alignment of Beat Gestures and Prosodic Prominence in German | `-` | `-` |
| 23 | Creak Prevalence and Prosodic Context in Australian English | `-` | `-` |
| 24 | Speech Reduction: Position within French Prosodic Structure | `-` | `-` |

### Speech Production

| **No** | **Title** | **Repo** | **Paper** |
| ------ | --------- |:--------:|:---------:|
| 25 | Transvelar Nasal Coupling Contributing to Speaker Characteristics in Non-nasal Vowels | `-` | `-` |
| 26 | Speech Synthesis from Articulatory Movements Recorded by Real-time MRI | `-` | `-` |
| 27 |  The ART of Conversation: Measuring Phonetic Convergence and Deliberate Imitation in L2-Speech with a Siamese RNN | [![GitHub](https://img.shields.io/github/stars/byronthecoder/S-RNN-4-ART)](https://github.com/byronthecoder/S-RNN-4-ART) | [![arXiv](https://img.shields.io/badge/arXiv-2306.05088-b31b1b.svg)](https://arxiv.org/abs/2306.05088) |
| 28 | Did You See that? Exploring the Role of Vision in the Development of Consonant Feature Contrasts in Children with Cochlear Implants | `-` | `-` |

### Dysarthric Speech Assessment

| **No** | **Title** | **Repo** | **Paper** |
| ------ | --------- |:--------:|:---------:|
| 29 | Automatic Assessments of Dysarthric Speech: the Usability of Acoustic-phonetic Features | `-` | `-` |
| 30 | Classification of Multi-class Vowels and Fricatives from Patients Having Amyotrophic Lateral Sclerosis with Varied Levels of Dysarthria Severity | `-` | `-` |
| 31 | Parameter-efficient Dysarthric Speech Recognition using Adapter Fusion and Householder Transformation | `-` | [![arXiv](https://img.shields.io/badge/arXiv-2306.07090-b31b1b.svg)](https://arxiv.org/abs/2306.07090) |
| 32 | Few-shot Dysarthric Speech Recognition with Text-to-Speech Data Augmentation | `-` | [![idiap](https://img.shields.io/badge/idiap.ch.5055-FF6A00.svg)](http://publications.idiap.ch/index.php/publications/show/5055) |
| 33 | Latent Phrase Matching for Dysarthric Speech | `-` | [![arXiv](https://img.shields.io/badge/arXiv-2306.05446-b31b1b.svg)](https://arxiv.org/abs/2306.05446) |
| 34 | Speech Intelligibility Assessment of Dysarthric Speech by using Goodness of Pronunciation with Uncertainty Quantification | [![GitHub](https://img.shields.io/github/stars/juice500ml/dysarthria-gop)](https://github.com/juice500ml/dysarthria-gop) | [![arXiv](https://img.shields.io/badge/arXiv-2305.18392-b31b1b.svg)](https://arxiv.org/abs/2305.18392) |

### Speech Coding: Transmission

| **No** | **Title** | **Repo** | **Paper** |
| ------ | --------- |:--------:|:---------:|
| 35 | CQNV: A Combination of Coarsely Quantized Bitstream and Neural Vocoder for Low Rate Speech Coding | `-` | `-` |
| 36 | Target Speech Extraction with Conditional Diffusion Model | `-` | `-` |
| 37 | Towards Fully Quantized Neural Networks For Speech Enhancement | `-` | `-` |
| 38 |  Complex Image Generation SwinTransformer Network for Audio Denoising | [![GitHub](https://img.shields.io/github/stars/YoushanZhang/CoxImgSwinTransformer)](https://github.com/YoushanZhang/CoxImgSwinTransformer) | `-` |

### Speech Recognition: Signal Processing, Acoustic Modeling, Robustness, Adaptation

| **No** | **Title** | **Repo** | **Paper** |
| ------ | --------- |:--------:|:---------:|
| 39 | Using Text Injection to Improve Recognition of Personal Identifiers in Speech | `-` | `-` |
| 40 | Investigating Wav2Vec2 Context Representations and the Effects of Fine-tuning, a Case-study of a Finnish Model | [![GitHub](https://img.shields.io/github/stars/aalto-speech/Wav2vec2Interpretation)](https://github.com/aalto-speech/Wav2vec2Interpretation) | `-` |
| 41 | Transformer-based Speech Recognition Models for Oral History Archives in English, German, and Czech | `-` | `-` |
| 42 | Iteratively Improving Speech Recognition and Voice Conversion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://demosamplesites.github.io/IterativeASR_VC/) | [![arXiv](https://img.shields.io/badge/arXiv-2305.15055-b31b1b.svg)](https://arxiv.org/abs/2305.15055) |
| 43 | LABERT: A Combination of Local Aggregation and Self-Supervised Speech Representation Learning for Detecting Informative Hidden Units in Low-Resource ASR Systems | `-` | [![nottingham-repo](https://img.shields.io/badge/nottingham-22183323-1A296B.svg)](https://nottingham-repository.worktribe.com/output/22183323) |
| 44 | TranUSR: Phoneme-to-word Transcoder Based Unified Speech Representation Learning for Cross-lingual Speech Recognition | `-` | [![arXiv](https://img.shields.io/badge/arXiv-2305.13629-b31b1b.svg)](https://arxiv.org/abs/2305.13629) |
| 45 | Dual-Mode NAM: Effective Top-K Context Injection for End-to-End ASR | `-` | `-` |
| 46 | GhostRNN: Reducing State Redundancy in RNN with Cheap Operations | `-` | `-` |
| 47 | Task-Agnostic Structured Pruning of Speech Representation Models | `-` | [![arXiv](https://img.shields.io/badge/arXiv-2306.01385-b31b1b.svg)](https://arxiv.org/abs/2306.01385) |
| 48 | Factual Consistency Oriented Speech Recognition | `-` | [![arXiv](https://img.shields.io/badge/arXiv-2302.12369-b31b1b.svg)](https://arxiv.org/abs/2302.12369) |
| 49 | Multi-Head State Space Model for Speech Recognition | | |
| 50 | Cascaded Multi-task Adaptive Learning Based on Neural Architecture Search | | |
| 51 | Probing Self-supervised Speech Models for Phonetic and Phonemic Information: a Case Study in Aspiration | | |
| 52 | Selective Biasing with Trie-based Contextual Adapters for Personalised Speech Recognition using Neural Transducers | | |

### Analysis of Speech and Audio Signals

> Will soon be added

### Speech Recognition: Architecture, Search, and Linguistic Components

> Will soon be added

### Speech Recognition: Technologies and Systems for New Applications

> Will soon be added

### Lexical and Language Modeling for ASR

> Will soon be added

### Language Identification and Diarization

> Will soon be added

### Speech Quality Assessment

> Will soon be added

### Feature Modeling for ASR

> Will soon be added

### Interfacing Speech Technology and Phonetics

> Will soon be added

### Speech Synthesis: Multilinguality

> Will soon be added

### Speech Emotion Recognition

> Will soon be added

### Spoken Dialog Systems and Conversational Analysis

> Will soon be added

### Speech Coding and Enhancement

> Will soon be added

### Paralinguistics

> Will soon be added

### Speech Enhancement and Denoising

> Will soon be added

### Speech Synthesis: Evaluation

> Will soon be added

### End-to-end Spoken Dialog Systems

> Will soon be added

### Biosignal-enabled Spoken Communication

> Will soon be added

### Neural-based Speech and Acoustic Analysis

> Will soon be added

### DiGo - Dialog for Good: Speech and Language Technology for Social Good

> Will soon be added

### Spoken Language Processing: Translation, Information Retrieval, Summarization, Resources, and Evaluation

> Will soon be added

### Speech, Voice, and Hearing Disorders

> Will soon be added

### Spoken Term Detection and Voice Search

> Will soon be added

### Models for Streaming ASR

> Will soon be added

### Source Separation

> Will soon be added

### Speech Perception

> Will soon be added

### Phonetics and Phonology: Languages and Varieties

> Will soon be added

### Speaker and Language Identification

> Will soon be added

### Speech Synthesis and Voice Conversion

> Will soon be added

### Speech and Language in Health: From Remote Monitoring to Medical Conversations

> Will soon be added

### Novel Transformer Models for ASR

> Will soon be added

### Speaker Recognition

> Will soon be added

### Cross-lingual and Multilingual ASR

> Will soon be added

### Voice Conversion

> Will soon be added

### Pathological Speech Analysis

> Will soon be added

### Multimodal Speech Emotion Recognition

> Will soon be added

### Phonetics, Phonology, and Prosody

> Will soon be added

### Speech Coding: Privacy

> Will soon be added

### Analysis of Neural Speech Representations

> Will soon be added

### End-to-end ASR

> Will soon be added

### Spoken Language Understanding, Summarization, and Information Retrieval

> Will soon be added

### Invariant and Robust Pre-trained Acoustic Models

> Will soon be added

### Speech Synthesis: Representation Learning

> Will soon be added

### Speech Perception, Production, and Acquisition

> Will soon be added

### Acoustic Model Adaptation for ASR

> Will soon be added

### Speech Synthesis: Expressivity

> Will soon be added

### Multi-modal Systems

> Will soon be added

### Question Answering from Speech

> Will soon be added

### Multi-talker Methods in Speech Processing

> Will soon be added

### Sociophonetics

> Will soon be added

### Speaker and Language Diarization

> Will soon be added

### Anti-Spoofing for Speaker Verification

> Will soon be added

### Speech Coding: Intelligibility

> Will soon be added

### Resources for Spoken Language Processing

> Will soon be added

### New Computational Strategies for ASR Training and Inference

> Will soon be added

### MERLIon CCS Challenge: Multilingual Everyday Recordings - Language Identification On Code-Switched Child- Directed Speech

> Will soon be added

### Health-Related Speech Analysis

> Will soon be added

### Automatic Audio Classification and Audio Captioning

> Will soon be added

### Speech Synthesis

> Will soon be added

### Speech Synthesis: Controllability and Adaptation

> Will soon be added

### Search Methods and Decoding Algorithms for ASR

> Will soon be added

### Speech Signal Analysis

> Will soon be added

### Connecting Speech-science and Speech-technology for Children's Speech

> Will soon be added

### Dialog Management

> Will soon be added

### Speech Activity Detection and Modeling

> Will soon be added

### Multilingual Models for ASR

> Will soon be added

### Speech Enhancement and Bandwidth Expansion

> Will soon be added

### Articulation

> Will soon be added

### Neural Processing of Speech and Language: Encoding and Decoding the Diverse Auditory Brain

> Will soon be added

### Perception of Paralinguistics

> Will soon be added

### Technologies for Child Speech Processing

> Will soon be added

### Speech Synthesis: Multilinguality; Evaluation

> Will soon be added
