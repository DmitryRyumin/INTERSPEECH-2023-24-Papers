# INTERSPEECH-2023-Papers

![GitHub repo size](https://img.shields.io/github/repo-size/DmitryRyumin/INTERSPEECH-2023-Papers)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers/blob/main/LICENSE)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat)](https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers/blob/main/README.md)
![GitHub last commit](https://img.shields.io/github/last-commit/DmitryRyumin/INTERSPEECH-2023-Papers)
<!-- ![Papers Implemented](https://badgen.net/badge/Papers%20implemented/0) -->

---

INTERSPEECH 2023 Papers: A complete collection of influential and exciting research papers from the [*INTERSPEECH 2023*](https://interspeech2023.org/) conference. Explore the latest advances in speech and language processing. Code included. :star: the repository to support the advancement of speech technology!

<p align="center">
    <a href="https://interspeech2023.org/" target="_blank">
        <img width="400" src="https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers/blob/main/images/Interspeech2023-Stacked-Colour.png" alt="Interspeech 2023">
    </a>
<p>

---

## Contributors

<a href="https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=DmitryRyumin/INTERSPEECH-2023-Papers" />
</a>

<br />
<br />

Contributions to improve the completeness of this list are greatly appreciated. If you come across any overlooked papers, please **feel free to [*create pull requests*](https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers/pulls), [*open issues*](https://github.com/DmitryRyumin/INTERSPEECH-2023-Papers/issues) or contact me via [*email*](mailto:ryumin.d@iias.spb.su)**. Your participation is crucial to making this repository even better.

---

## Papers

### Speech Synthesis: Prosody and Emotion

| **#** | **Title** | **Repo** | **Paper** |
| ----- | --------- |:--------:|:---------:|
| 749 | Emotional Talking Head Generation based on Memory-Sharing and Attention-Augmented Networks | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.03594-b31b1b.svg)](https://arxiv.org/abs/2306.03594) |
| 1292 | Speech Synthesis with Self-Supervisedly Learnt Prosodic Representations | :heavy_minus_sign: | :heavy_minus_sign: |
| 1317 | EmoMix: Emotion Mixing via Diffusion Models for Emotional Speech Synthesis | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.00648-b31b1b.svg)](https://arxiv.org/abs/2306.00648) |
| 806 | Laughter Synthesis using Pseudo Phonetic Tokens with a Large-scale In-the-wild Laughter Corpus | [![GitHub](https://img.shields.io/github/stars/Aria-K-Alethia/laughter-synthesis)](https://github.com/Aria-K-Alethia/laughter-synthesis) | [![arXiv](https://img.shields.io/badge/arXiv-2305.12442-b31b1b.svg)](https://arxiv.org/abs/2305.12442) |
| 2270 | Explicit Intensity Control for Accented Text-to-speech | [![GitHub](https://img.shields.io/github/stars/ttslr/Ai-TTS)](https://github.com/ttslr/Ai-TTS) | [![arXiv](https://img.shields.io/badge/arXiv-2210.15364-b31b1b.svg)](https://arxiv.org/abs/2210.15364) |
| 834 | Comparing Normalizing Flows and Diffusion Models for Prosody and Acoustic Modelling in Text-to-speech | :heavy_minus_sign: | :heavy_minus_sign: |

### Statistical Machine Translation

| **#** | **Title** | **Repo** | **Paper** |
| ----- | --------- |:--------:|:---------:|
| 2484 | Modular Speech-to-Text Translation for Zero-Shot Cross-Modal Transfer | :heavy_minus_sign: | :heavy_minus_sign: |
| 1063 | Improving Isochronous Machine Translation with Target Factors and Auxiliary Counters | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2305.13204-b31b1b.svg)](https://arxiv.org/abs/2305.13204) |
| 648 | StyleS2ST: Zero-shot Style Transfer for Direct Speech-to-speech Translation | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://styles2st.github.io/StyleS2ST/) | [![arXiv](https://img.shields.io/badge/arXiv-2305.17732-b31b1b.svg)](https://arxiv.org/abs/2305.17732) |
| 1767 | Joint Speech Translation and Named Entity Recognition | [![GitHub](https://img.shields.io/github/stars/hlt-mt/FBK-fairseq)](https://github.com/hlt-mt/FBK-fairseq/blob/master/fbk_works/JOINT_ST_NER2023.md) | [![arXiv](https://img.shields.io/badge/arXiv-2210.11987-b31b1b.svg)](https://arxiv.org/abs/2210.11987) |
| 2050 | Analysis of Acoustic information in End-to-End Spoken Language Translation | :heavy_minus_sign: | :heavy_minus_sign: |
| 2004 | LAMASSU: A Streaming Language-Agnostic Multilingual Speech Recognition and Translation Model Using Neural Transducers | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2211.02809-b31b1b.svg)](https://arxiv.org/abs/2211.02809) |

### Self-Supervised Learning in ASR

| **#** | **Title** | **Repo** | **Paper** |
| ----- | --------- |:--------:|:---------:|
| 1213 | DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models | [![GitHub](https://img.shields.io/github/stars/pyf98/DPHuBERT)](https://github.com/pyf98/DPHuBERT) | [![arXiv](https://img.shields.io/badge/arXiv-2305.17651-b31b1b.svg)](https://arxiv.org/abs/2305.17651) |
| 1040 | Automatic Data Augmentation for Domain Adapted Fine-Tuning of Self-Supervised Speech Representations | [![GitHub](https://img.shields.io/github/stars/salah-zaiem/augmentations_adaptation)](https://github.com/salah-zaiem/augmentations_adaptation) | [![arXiv](https://img.shields.io/badge/arXiv-2306.00481-b31b1b.svg)](https://arxiv.org/abs/2306.00481) |
| 387 | Dual Acoustic Linguistic Self-supervised Representation Learning for Cross-Domain Speech Recognition | :heavy_minus_sign: | :heavy_minus_sign: |
| 2166 | O-1: Self-training with Oracle and 1-best Hypothesis | :heavy_minus_sign: | :heavy_minus_sign: |
| 822 | MT4SSL: Boosting Self-Supervised Speech Representation Learning by Integrating Multiple Targets | [![GitHub](https://img.shields.io/github/stars/ddlBoJack/MT4SSL)](https://github.com/ddlBoJack/MT4SSL) | [![arXiv](https://img.shields.io/badge/arXiv-2211.07321-b31b1b.svg)](https://arxiv.org/abs/2211.07321) |
| 1802 | Comparison of Multilingual Self-Supervised and Weakly-Supervised Speech Pre-Training for Adaptation to Unseen Languages | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2305.12606-b31b1b.svg)](https://arxiv.org/abs/2305.12606) |

### Prosody

| **#** | **Title** | **Repo** | **Paper** |
| ----- | --------- |:--------:|:---------:|
| 1781 | Chinese EFL Learners' Perception of English Prosodic Focus | :heavy_minus_sign: | :heavy_minus_sign: |
| 315 | Pitch Accent Variation and the Interpretation of Rising and Falling Intonation in American English | :heavy_minus_sign: | :heavy_minus_sign: |
| 1033 | Tonal Coarticulation as a Cue for Upcoming Prosodic Boundary | :heavy_minus_sign: | :heavy_minus_sign: |
| 2116 | Alignment of Beat Gestures and Prosodic Prominence in German | :heavy_minus_sign: | :heavy_minus_sign: |
| 1454 | Creak Prevalence and Prosodic Context in Australian English | :heavy_minus_sign: | :heavy_minus_sign: |
| 1651 | Speech Reduction: Position within French Prosodic Structure | :heavy_minus_sign: | :heavy_minus_sign: |

### Speech Production

| **#** | **Title** | **Repo** | **Paper** |
| ----- | --------- |:--------:|:---------:|
| 637 | Transvelar Nasal Coupling Contributing to Speaker Characteristics in Non-nasal Vowels | :heavy_minus_sign: | :heavy_minus_sign: |
| 286 | Speech Synthesis from Articulatory Movements Recorded by Real-time MRI | :heavy_minus_sign: | :heavy_minus_sign: |
| 2283 |  The ART of Conversation: Measuring Phonetic Convergence and Deliberate Imitation in L2-Speech with a Siamese RNN | [![GitHub](https://img.shields.io/github/stars/byronthecoder/S-RNN-4-ART)](https://github.com/byronthecoder/S-RNN-4-ART) | [![arXiv](https://img.shields.io/badge/arXiv-2306.05088-b31b1b.svg)](https://arxiv.org/abs/2306.05088) |
| 1933 | Did You See that? Exploring the Role of Vision in the Development of Consonant Feature Contrasts in Children with Cochlear Implants | :heavy_minus_sign: | :heavy_minus_sign: |

### Dysarthric Speech Assessment

| **#** | **Title** | **Repo** | **Paper** |
| ----- | --------- |:--------:|:---------:|
| 2017 | Automatic Assessments of Dysarthric Speech: the Usability of Acoustic-phonetic Features | :heavy_minus_sign: | :heavy_minus_sign: |
| 1455 | Classification of Multi-class Vowels and Fricatives from Patients Having Amyotrophic Lateral Sclerosis with Varied Levels of Dysarthria Severity | :heavy_minus_sign: | :heavy_minus_sign: |
| 1627 | Parameter-efficient Dysarthric Speech Recognition using Adapter Fusion and Householder Transformation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.07090-b31b1b.svg)](https://arxiv.org/abs/2306.07090) |
| 2481 | Few-shot Dysarthric Speech Recognition with Text-to-Speech Data Augmentation | :heavy_minus_sign: | [![idiap](https://img.shields.io/badge/idiap.ch.5055-FF6A00.svg)](http://publications.idiap.ch/index.php/publications/show/5055) |
| 1921 | Latent Phrase Matching for Dysarthric Speech | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.05446-b31b1b.svg)](https://arxiv.org/abs/2306.05446) |
| 173 | Speech Intelligibility Assessment of Dysarthric Speech by using Goodness of Pronunciation with Uncertainty Quantification | [![GitHub](https://img.shields.io/github/stars/juice500ml/dysarthria-gop)](https://github.com/juice500ml/dysarthria-gop) | [![arXiv](https://img.shields.io/badge/arXiv-2305.18392-b31b1b.svg)](https://arxiv.org/abs/2305.18392) |

### Speech Coding: Transmission

| **#** | **Title** | **Repo** | **Paper** |
| ----- | --------- |:--------:|:---------:|
| 1562 | CQNV: A Combination of Coarsely Quantized Bitstream and Neural Vocoder for Low Rate Speech Coding | :heavy_minus_sign: | :heavy_minus_sign: |
| 1234 | Target Speech Extraction with Conditional Diffusion Model | :heavy_minus_sign: | :heavy_minus_sign: |
| 883 | Towards Fully Quantized Neural Networks For Speech Enhancement | :heavy_minus_sign: | :heavy_minus_sign: |
| 980 |  Complex Image Generation SwinTransformer Network for Audio Denoising | [![GitHub](https://img.shields.io/github/stars/YoushanZhang/CoxImgSwinTransformer)](https://github.com/YoushanZhang/CoxImgSwinTransformer) | :heavy_minus_sign: |

### Speech Recognition: Signal Processing, Acoustic Modeling, Robustness, Adaptation

| **#** | **Title** | **Repo** | **Paper** |
| ----- | --------- |:--------:|:---------:|
| 2118 | Using Text Injection to Improve Recognition of Personal Identifiers in Speech | :heavy_minus_sign: | :heavy_minus_sign: |
| 837 | Investigating Wav2Vec2 Context Representations and the Effects of Fine-tuning, a Case-study of a Finnish Model | [![GitHub](https://img.shields.io/github/stars/aalto-speech/Wav2vec2Interpretation)](https://github.com/aalto-speech/Wav2vec2Interpretation) | :heavy_minus_sign: |
| 872 | Transformer-based Speech Recognition Models for Oral History Archives in English, German, and Czech | :heavy_minus_sign: | :heavy_minus_sign: |
| 177 | Iteratively Improving Speech Recognition and Voice Conversion | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://demosamplesites.github.io/IterativeASR_VC/) | [![arXiv](https://img.shields.io/badge/arXiv-2305.15055-b31b1b.svg)](https://arxiv.org/abs/2305.15055) |
| 2001 | LABERT: A Combination of Local Aggregation and Self-Supervised Speech Representation Learning for Detecting Informative Hidden Units in Low-Resource ASR Systems | :heavy_minus_sign: | [![nottingham-repo](https://img.shields.io/badge/nottingham-22183323-1A296B.svg)](https://nottingham-repository.worktribe.com/output/22183323) |
| 746 | TranUSR: Phoneme-to-word Transcoder Based Unified Speech Representation Learning for Cross-lingual Speech Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2305.13629-b31b1b.svg)](https://arxiv.org/abs/2305.13629) |
| 1124 | Dual-Mode NAM: Effective Top-K Context Injection for End-to-End ASR | :heavy_minus_sign: | :heavy_minus_sign: |
| 2417 | GhostRNN: Reducing State Redundancy in RNN with Cheap Operations | :heavy_minus_sign: | :heavy_minus_sign: |
| 1442 | Task-Agnostic Structured Pruning of Speech Representation Models | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.01385-b31b1b.svg)](https://arxiv.org/abs/2306.01385) |
| 485 | Factual Consistency Oriented Speech Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2302.12369-b31b1b.svg)](https://arxiv.org/abs/2302.12369) |
| 1036 | Multi-Head State Space Model for Speech Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2305.12498-b31b1b.svg)](https://arxiv.org/abs/2305.12498) |
| 341 | Cascaded Multi-task Adaptive Learning Based on Neural Architecture Search | :heavy_minus_sign: | :heavy_minus_sign: |
| 2359 | Probing Self-supervised Speech Models for Phonetic and Phonemic Information: a Case Study in Aspiration | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.06232-b31b1b.svg)](https://arxiv.org/abs/2306.06232) |
| 739 | Selective Biasing with Trie-based Contextual Adapters for Personalised Speech Recognition using Neural Transducers | :heavy_minus_sign: | [![Amazon Science](https://img.shields.io/badge/amazon-science-FE9901.svg)](https://www.amazon.science/publications/selective-biasing-with-trie-based-contextual-adapters-for-personalised-speech-recognition-using-neural-transducers) |

### Analysis of Speech and Audio Signals

| **#** | **Title** | **Repo** | **Paper** |
| ----- | --------- |:--------:|:---------:|
| 1173 | Robust Prototype Learning for Anomalous Sound Detection | :heavy_minus_sign: | :heavy_minus_sign: |
| 982 | A Multimodal Prototypical Approach for Unsupervised Sound Classification | [![GitHub](https://img.shields.io/github/stars/sakshamsingh1/audio_text_proto)](https://github.com/sakshamsingh1/audio_text_proto) | [![arXiv](https://img.shields.io/badge/arXiv-2306.12300-b31b1b.svg)](https://arxiv.org/abs/2306.12300) |
| 563 | Robust Audio Anti-Spoofing with Fusion-Reconstruction Learning on Multi-Order Spectrograms | :heavy_minus_sign: | :heavy_minus_sign: |
| 1082 | Adapting Language-Audio Models as Few-Shot Audio Learners | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2305.17719-b31b1b.svg)](https://arxiv.org/abs/2305.17719) |
| 914 | Visually-Aware Audio Captioning With Adaptive Audio-Visual Attention | [![GitHub](https://img.shields.io/github/stars/liuxubo717/V-ACT)](https://github.com/liuxubo717/V-ACT) | [![arXiv](https://img.shields.io/badge/arXiv-2210.16428-b31b1b.svg)](https://arxiv.org/abs/2210.16428) |
| 734 | TFECN: Time-Frequency Enhanced ConvNet for Audio Classification | :heavy_minus_sign: | :heavy_minus_sign: |
| 350 | Resolution Consistency Training on Time-Frequency Domain for Semi-Supervised Sound Event Detection | :heavy_minus_sign: | :heavy_minus_sign: |
| 1174 | Fine-tuning Audio Spectrogram Transformer with Task-aware Adapters for Sound Event Detection | :heavy_minus_sign: | :heavy_minus_sign: |
| 1210 | Small Footprint Multi-channel Network for Keyword Spotting with Centroid Based Awareness | :heavy_minus_sign: | :heavy_minus_sign: |
| 1380 | Few-shot Class-incremental Audio Classification Using Adaptively-refined Prototypes | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2305.18045-b31b1b.svg)](https://arxiv.org/abs/2305.18045) |
| 1549 | Interpretable Latent Space Using Space-Filling Curves for Phonetic Analysis in Voice Conversion | [![GitLab](https://img.shields.io/gitlab/stars/speech-interaction-technology-aalto-university/sfvq)](https://gitlab.com/speech-interaction-technology-aalto-university/sfvq) | [![Aalto](https://img.shields.io/badge/aalto-fi-005EB8.svg)](https://research.aalto.fi/en/publications/interpretable-latent-space-using-space-filling-curves-for-phoneti) |
| 1861 | Topological Data Analysis for Speech Processing | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://topohubert.github.io/speech-topology-webpages/) | [![arXiv](https://img.shields.io/badge/arXiv-2211.17223-b31b1b.svg)](https://arxiv.org/abs/2211.17223) |
| 1329 | Recycle-and-Distill: Universal Compression Strategy for Transformer-based Speech SSL Models with Attention Map Reusing and Masking Distillation | [![GitHub](https://img.shields.io/github/stars/sungnyun/ARMHuBERT)](https://github.com/sungnyun/ARMHuBERT) | [![arXiv](https://img.shields.io/badge/arXiv-2305.11685-b31b1b.svg)](https://arxiv.org/abs/2305.11685) |
| 932 | Personalized Acoustic Scene Classification in Ultra-low Power Embedded Devices using Privacy-preserving Data Augmentation | :heavy_minus_sign: | :heavy_minus_sign: |
| 176 | Background Domain Switch: A Novel Data Augmentation Technique for Robust Sound Event Detection | :heavy_minus_sign: | :heavy_minus_sign: |
| 1021 | Joint Prediction of Audio Event and Annoyance Rating in an Urban Soundscape by Hierarchical Graph Representation Learning | [![GitHub](https://img.shields.io/github/stars/Yuanbo2020/HGRL)](https://github.com/Yuanbo2020/HGRL) | [![Pdf](https://img.shields.io/badge/pdf-version-003B10.svg)](http://personal.ee.surrey.ac.uk/Personal/W.Wang/papers/Hou%20etal_INTERSPEECH_2023.pdf) |
| 2416 | Anomalous Sound Detection Using Self-Attention-Based Frequency Pattern Analysis of Machine Sounds | :heavy_minus_sign: | :heavy_minus_sign: |
| 1478 | Improving Audio-Text Retrieval via Hierarchical Cross-Modal Interaction and Auxiliary Captions | :heavy_minus_sign: | :heavy_minus_sign: |
| 979 | Ontology-aware Learning and Evaluation for Audio Tagging | [![GitHub](https://img.shields.io/github/stars/haoheliu/ontology-aware-audio-tagging)](https://github.com/haoheliu/ontology-aware-audio-tagging) | [![arXiv](https://img.shields.io/badge/arXiv-2211.12195-b31b1b.svg)](https://arxiv.org/abs/2211.12195) |
| 575 | Differential Privacy enabled Dementia Classification: An Exploration of the Privacy-Accuracy Trade-off in Speech Signal Data | :heavy_minus_sign: | :heavy_minus_sign: |
| 1595 | Learning Emotional Representations from Imbalanced Speech Data for Speech Emotion Recognition and Emotional Text-to-Speech | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://anonymous.4open.science/w/INTERSPEECH2023-F8C4/) | [![arXiv](https://img.shields.io/badge/arXiv-2306.05709-b31b1b.svg)](https://arxiv.org/abs/2306.05709) |
| 1816 | Towards Multi-Lingual Audio Question Answering | :heavy_minus_sign: | :heavy_minus_sign: |

### Speech Recognition: Architecture, Search, and Linguistic Components

| **#** | **Title** | **Repo** | **Paper** |
| ----- | --------- |:--------:|:---------:|
| 2344 | Diacritic Recognition Performance in Arabic ASR | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2302.14022-b31b1b.svg)](https://arxiv.org/abs/2302.14022) |
| 990 | Personalization for BERT-based Discriminative Speech Recognition Rescoring | :heavy_minus_sign: | [![Amazon Science](https://img.shields.io/badge/amazon-science-FE9901.svg)](https://www.amazon.science/publications/personalization-for-bert-based-discriminative-speech-recognition-rescoring) |
| 2182 | On the N-gram Approximation of Pre-trained Language Models | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.06892-b31b1b.svg)](https://arxiv.org/abs/2306.06892) |
| 2147 | Record Deduplication for Entity Distribution Modeling in ASR Transcripts | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.06246-b31b1b.svg)](https://arxiv.org/abs/2306.06246) |
| 2205 | Learning When to Trust Which Teacher for Weakly Supervised ASR | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.12012-b31b1b.svg)](https://arxiv.org/abs/2306.12012) |
| 1313 | Text-only Domain Adaptation using Unified Speech-Text Representation in Transducer | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.04076-b31b1b.svg)](https://arxiv.org/abs/2306.04076) |

### Speech Recognition: Technologies and Systems for New Applications

| **#** | **Title** | **Repo** | **Paper** |
| ----- | --------- |:--------:|:---------:|
| 1079 | How to Estimate Model Transferability of Pre-Trained Speech Models? | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.01015-b31b1b.svg)](https://arxiv.org/abs/2306.01015) |
| 235 | Progress and Prospects for Spoken Language Technology: Results from Five Sexennial Surveys | :heavy_minus_sign: | :heavy_minus_sign: |
| 268 | Acoustic Word Embeddings for Untranscribed Target Languages with Continued Pretraining and Learned Pooling | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.02153-b31b1b.svg)](https://arxiv.org/abs/2306.02153) |
| 601 | CASA-ASR: Context-Aware Speaker-Attributed ASR | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2305.12459-b31b1b.svg)](https://arxiv.org/abs/2305.12459) |
| 1321 | Unsupervised Learning of Discrete Latent Representations with Data-Adaptive Dimensionality from Continuous Speech Streams | :heavy_minus_sign: | :heavy_minus_sign: |
| 1167 | AD-TUNING: An Adaptive CHILD-TUNING Approach to Efficient Hyperparameter Optimization of Child Networks for Speech Processing Tasks in the SUPERB Benchmark | [![GitHub](https://img.shields.io/github/stars/liyunlongaaa/AD-TUNING)](https://github.com/liyunlongaaa/AD-TUNING) | :heavy_minus_sign: |
| 190 | Distilling Knowledge from Gaussian Process Teacher to Neural Network Student | :heavy_minus_sign: | :heavy_minus_sign: |
| 2032 | Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization | [![GitHub](https://img.shields.io/github/stars/jasonppy/PromptingWhisper)](https://github.com/jasonppy/PromptingWhisper) | [![arXiv](https://img.shields.io/badge/arXiv-2305.11095-b31b1b.svg)](https://arxiv.org/abs/2305.11095) |
| 135 | Segmental SpeechCLIP: Utilizing Pretrained Image-text Models for Audio-Visual Learning | :heavy_minus_sign: | :heavy_minus_sign: |
| 421 | Towards Hate Speech Detection in Low-resource Languages: Comparing ASR to Acoustic Word Embeddings on Wolof and Swahili | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.00410-b31b1b.svg)](https://arxiv.org/abs/2306.00410) |
| 385 | Mitigating Catastrophic Forgetting for Few-Shot Spoken Word Classification Through Meta-Learning | [![GitHub](https://img.shields.io/github/stars/ByteFuse/MAMLCon)](https://github.com/ByteFuse/MAMLCon) | [![arXiv](https://img.shields.io/badge/arXiv-2305.13080-b31b1b.svg)](https://arxiv.org/abs/2305.13080) |
| 664 | Online Punctuation Restoration using ELECTRA Model for streaming ASR Systems | :heavy_minus_sign: | :heavy_minus_sign: |
| 2066 | Language Agnostic Data-Driven Inverse Text Normalization | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2301.08506-b31b1b.svg)](https://arxiv.org/abs/2301.08506) |
| 2044 | Syllable Discovery and Cross-Lingual Generalization in a Visually Grounded, Self-Supervised Speech Model | [![GitHub](https://img.shields.io/github/stars/jasonppy/syllable-discovery)](https://github.com/jasonppy/syllable-discovery) | [![arXiv](https://img.shields.io/badge/arXiv-2305.11435-b31b1b.svg)](https://arxiv.org/abs/2305.11435) |
| 1655 | Transcribing Speech as Spoken and Written Dual Text Using an Autoregressive Model | :heavy_minus_sign: | :heavy_minus_sign: |

### Lexical and Language Modeling for ASR

| **#** | **Title** | **Repo** | **Paper** |
| ----- | --------- |:--------:|:---------:|
| 643 | NoRefER: a Referenceless Quality Metric for Automatic Speech Recognition via Semi-Supervised Language Model Fine-Tuning with Contrastive Learning | [![GitHub](https://img.shields.io/github/stars/aixplain/NoRefER)](https://github.com/aixplain/NoRefER) | [![arXiv](https://img.shields.io/badge/arXiv-2306.12577-b31b1b.svg)](https://arxiv.org/abs/2306.12577) |
| 2128 | Scaling Laws for Discriminative Speech Recognition Rescoring Models | :heavy_minus_sign: | [![Amazon Science](https://img.shields.io/badge/amazon-science-FE9901.svg)](https://www.amazon.science/publications/scaling-laws-for-discriminative-speech-recognition-rescoring-models) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2306.15815-b31b1b.svg)](https://arxiv.org/abs/2306.15815) |
| 2429 | Exploring Energy-based Language Models with Different Architectures and Training Methods for Speech Recognition | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://github.com/thu-spmi/CAT/blob/master/docs/energy-based_LM_training.md) | [![arXiv](https://img.shields.io/badge/arXiv-2305.12676-b31b1b.svg)](https://arxiv.org/abs/2305.12676) |
| 1362 | Memory Augmented Lookup Dictionary based Language Modeling for Automatic Speech Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2301.00066-b31b1b.svg)](https://arxiv.org/abs/2301.00066) |
| 1251 | Memory Network-Based End-To-End Neural ES-KMeans for Improved Word Segmentation | :heavy_minus_sign: | :heavy_minus_sign: |
| 1320 | Retraining-free Customized ASR for Enharmonic Words Based on a Named-Entity-Aware Model and Phoneme Similarity Estimation | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2305.17846-b31b1b.svg)](https://arxiv.org/abs/2305.17846) |

### Language Identification and Diarization

| **#** | **Title** | **Repo** | **Paper** |
| ----- | --------- |:--------:|:---------:|
| 304 | Lightweight and Efficient Spoken Language Identification of Long-form Audio | :heavy_minus_sign: | :heavy_minus_sign: |
| 1109 | End-to-End Spoken Language Diarization with Wav2vec Embeddings | :heavy_minus_sign: | :heavy_minus_sign: |
| 1986 | Efficient Spoken Language Recognition via Multilabel Classification | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.01945-b31b1b.svg)](https://arxiv.org/abs/2306.01945) |
| 1529 | Description and Analysis of ABC Submission to NIST LRE 2022 | :heavy_minus_sign: | :heavy_minus_sign: |
| 1790 | Exploring the Impact of Pretrained Models and Web-Scraped Data for the 2022 NIST Language Recognition Evaluation | :heavy_minus_sign: | :heavy_minus_sign: |
| 1094 | Advances in Language Recognition in Low Resource African Languages: The JHU-MIT Submission for NIST LRE22 | :heavy_minus_sign: | :heavy_minus_sign: |

### Speech Quality Assessment

| **#** | **Title** | **Repo** | **Paper** |
| ----- | --------- |:--------:|:---------:|
| 1436 | DeePMOS: Deep Posterior Mean-Opinion-Score of Speech | :heavy_minus_sign: | :heavy_minus_sign: |
| 1644 | The Role of Formant and Excitation Source Features in Perceived Naturalness of Low Resource Tribal Language TTS: An Empirical Study | :heavy_minus_sign: | :heavy_minus_sign: |
| 811 | A No-reference Speech Quality Assessment Method based on Neural Network with Densely Connected Convolutional Architecture | :heavy_minus_sign: | :heavy_minus_sign: |
| 2507 | Probing Speech Quality Information in ASR Systems | :heavy_minus_sign: | :heavy_minus_sign: |
| 589 | Preference-based Training Framework for Automatic Speech Quality Assessment using Deep Neural Network | :heavy_minus_sign: | :heavy_minus_sign: |
| 389 | Crowdsourced Data Validation for ASR Training | :heavy_minus_sign: | :heavy_minus_sign: |

### Feature Modeling for ASR

| **#** | **Title** | **Repo** | **Paper** |
| ----- | --------- |:--------:|:---------:|
| 2296 | Re-investigating the Efficient Transfer Learning of Speech Foundation Model using Feature Fusion Methods | :heavy_minus_sign: | :heavy_minus_sign: |
| 1556 | Robust Automatic Speech Recognition via WavAugment Guided Phoneme Adversarial Training | :heavy_minus_sign: | :heavy_minus_sign: |
| 509 | InterFormer: Interactive Local and Global Features Fusion for Automatic Speech Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2305.16342-b31b1b.svg)](https://arxiv.org/abs/2305.16342) |
| 579 | Transductive Feature Space Regularization for Few-shot Bioacoustic Event Detection | :heavy_minus_sign: | :heavy_minus_sign: |
| 615 | Incorporating L2 Phonemes Using Articulatory Features for Robust Speech Recognition | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.02534-b31b1b.svg)](https://arxiv.org/abs/2306.02534) |
| 1510 | On the (In)Efficiency of Acoustic Feature Extractors for Self-Supervised Speech Representation Learning | :heavy_minus_sign: | [![HAL Science](https://img.shields.io/badge/hal-science-040060.svg)](https://hal.science/hal-04116371) |

### Interfacing Speech Technology and Phonetics

| **#** | **Title** | **Repo** | **Paper** |
| ----- | --------- |:--------:|:---------:|
| 1846 | Phonemic Competition in End-to-end ASR models | :heavy_minus_sign: | :heavy_minus_sign: |
| 443 | Automatic Speaker Recognition with Variation Across Vocal Conditions: a Controlled Experiment with Implications for Forensics | :heavy_minus_sign: | :heavy_minus_sign: |
| 1398 | Exploring Graph Theory Methods for the Analysis of Pronunciation Variation in Spontaneous Speech | :heavy_minus_sign: | :heavy_minus_sign: |
| 680 | Automatic Speaker Recognition Performance with Matched and Mismatched Female Bilingual Speech Data | :heavy_minus_sign: | :heavy_minus_sign: |

### Speech Synthesis: Multilinguality

| **#** | **Title** | **Repo** | **Paper** |
| ----- | --------- |:--------:|:---------:|
| 2303 | FACTSpeech: Speaking a Foreign Language Pronunciation Using Only Your Native Characters | :heavy_minus_sign: | :heavy_minus_sign: |
| 934 | Cross-Lingual Transfer Learning for Phrase Break Prediction with Multilingual Language Model | :heavy_minus_sign: | [![arXiv](https://img.shields.io/badge/arXiv-2306.02579-b31b1b.svg)](https://arxiv.org/abs/2306.02579) |
| 363 | DSE-TTS: Dual Speaker Embedding for Cross-Lingual Text-to-Speech | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://goarsenal.github.io/DSE-TTS/) | [![arXiv](https://img.shields.io/badge/arXiv-2306.14145-b31b1b.svg)](https://arxiv.org/abs/2306.14145) |
| 1467 | Generating Multilingual Gender-Ambiguous Text-to-Speech Voices | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://innoetics.github.io/publications/gender-ambiguous/index.html) | [![arXiv](https://img.shields.io/badge/arXiv-2211.00375-b31b1b.svg)](https://arxiv.org/abs/2211.00375) |
| 2330 | RADMMM: Multilingual Multiaccented Multispeaker Text to Speech | :heavy_minus_sign: | [![HAL Science](https://img.shields.io/badge/NVidia-AI-78B900.svg)](https://research.nvidia.com/labs/adlr/projects/radmmm/) |
| 861 | Multilingual Context-based Pronunciation Learning for Text-to-Speech | :heavy_minus_sign: | [![Amazon Science](https://img.shields.io/badge/amazon-science-FE9901.svg)](https://www.amazon.science/publications/multilingual-context-based-pronunciation-learning-for-text-to-speech) |

### Speech Emotion Recognition

> Will soon be added

### Spoken Dialog Systems and Conversational Analysis

> Will soon be added

### Speech Coding and Enhancement

> Will soon be added

### Paralinguistics

> Will soon be added

### Speech Enhancement and Denoising

> Will soon be added

### Speech Synthesis: Evaluation

> Will soon be added

### End-to-end Spoken Dialog Systems

> Will soon be added

### Biosignal-enabled Spoken Communication

> Will soon be added

### Neural-based Speech and Acoustic Analysis

> Will soon be added

### DiGo - Dialog for Good: Speech and Language Technology for Social Good

> Will soon be added

### Spoken Language Processing: Translation, Information Retrieval, Summarization, Resources, and Evaluation

> Will soon be added

### Speech, Voice, and Hearing Disorders

> Will soon be added

### Spoken Term Detection and Voice Search

> Will soon be added

### Models for Streaming ASR

> Will soon be added

### Source Separation

> Will soon be added

### Speech Perception

> Will soon be added

### Phonetics and Phonology: Languages and Varieties

> Will soon be added

### Speaker and Language Identification

> Will soon be added

### Speech Synthesis and Voice Conversion

> Will soon be added

### Speech and Language in Health: From Remote Monitoring to Medical Conversations

> Will soon be added

### Novel Transformer Models for ASR

> Will soon be added

### Speaker Recognition

> Will soon be added

### Cross-lingual and Multilingual ASR

> Will soon be added

### Voice Conversion

> Will soon be added

### Pathological Speech Analysis

> Will soon be added

### Multimodal Speech Emotion Recognition

> Will soon be added

### Phonetics, Phonology, and Prosody

> Will soon be added

### Speech Coding: Privacy

> Will soon be added

### Analysis of Neural Speech Representations

> Will soon be added

### End-to-end ASR

> Will soon be added

### Spoken Language Understanding, Summarization, and Information Retrieval

> Will soon be added

### Invariant and Robust Pre-trained Acoustic Models

> Will soon be added

### Speech Synthesis: Representation Learning

> Will soon be added

### Speech Perception, Production, and Acquisition

> Will soon be added

### Acoustic Model Adaptation for ASR

> Will soon be added

### Speech Synthesis: Expressivity

> Will soon be added

### Multi-modal Systems

> Will soon be added

### Question Answering from Speech

> Will soon be added

### Multi-talker Methods in Speech Processing

> Will soon be added

### Sociophonetics

> Will soon be added

### Speaker and Language Diarization

> Will soon be added

### Anti-Spoofing for Speaker Verification

> Will soon be added

### Speech Coding: Intelligibility

> Will soon be added

### Resources for Spoken Language Processing

> Will soon be added

### New Computational Strategies for ASR Training and Inference

> Will soon be added

### MERLIon CCS Challenge: Multilingual Everyday Recordings - Language Identification On Code-Switched Child- Directed Speech

> Will soon be added

### Health-Related Speech Analysis

> Will soon be added

### Automatic Audio Classification and Audio Captioning

> Will soon be added

### Speech Synthesis

> Will soon be added

### Speech Synthesis: Controllability and Adaptation

> Will soon be added

### Search Methods and Decoding Algorithms for ASR

> Will soon be added

### Speech Signal Analysis

> Will soon be added

### Connecting Speech-science and Speech-technology for Children's Speech

> Will soon be added

### Dialog Management

> Will soon be added

### Speech Activity Detection and Modeling

> Will soon be added

### Multilingual Models for ASR

> Will soon be added

### Speech Enhancement and Bandwidth Expansion

> Will soon be added

### Articulation

> Will soon be added

### Neural Processing of Speech and Language: Encoding and Decoding the Diverse Auditory Brain

> Will soon be added

### Perception of Paralinguistics

> Will soon be added

### Technologies for Child Speech Processing

> Will soon be added

### Speech Synthesis: Multilinguality; Evaluation

> Will soon be added
